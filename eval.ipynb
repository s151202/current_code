{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('D:\\Diamond\\code')\n",
    "from csp_james_2 import *\n",
    "\n",
    "sys.path.append('D:\\Diamond\\code')\n",
    "from thesis_funcs_19_03 import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import csv\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "meth = 'tl_comp_csp_mi' #gold_standï¼Œtl_comp_csp_kld , tl_comp_csp_mi\n",
    "raw_data_root = 'E:\\\\Diamond\\\\bci_iv\\\\DATA\\\\2a\\\\extract_raw\\\\'\n",
    "config_root= 'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\configs\\\\'\n",
    "\n",
    "feature_root = 'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\' + meth + '\\\\'\n",
    "model_root = feature_root\n",
    "save_root = model_root + 'eval\\\\'\n",
    "\n",
    "\n",
    "#load in cv config grid\n",
    "hp_names  =[] #all the hyper-parameter names to be validated\n",
    "with open(config_root +'cv_config.csv', mode = 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    for row in csv_reader:\n",
    "        hp_names.append((row[0]).strip())\n",
    "\n",
    "with open(config_root +'_lambda_config.csv', mode = 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    for row in csv_reader:\n",
    "        hp_names.append((row[0]).strip())\n",
    "csv_file.close()\n",
    "\n",
    "\n",
    "\n",
    "num_inits = 5\n",
    "k_fold = 10\n",
    "\n",
    "# initialize csp\n",
    "m = 2# m is Nw in the paper \"learning temporal information for brain-copmuter interface, Sakhavi et.al\"\n",
    "n_components = 2 * m  # pick some components\n",
    "down_sample_step = 20 #Hilbert evelope\n",
    "# select Ns pairs of csp filters\n",
    "Ns = 4\n",
    "\n",
    "CLASSES =[0,1]\n",
    "\n",
    "C_OVR = [0,1,2,3]\n",
    "\n",
    "balance_classes = 1\n",
    "\n",
    "########################################################################################################################\n",
    "                                            # DEFINE FILTER BANK\n",
    "########################################################################################################################\n",
    "#Filter Bank\n",
    "FB = [[4., 8.], [8., 12.], [12., 16.], [16., 20.], [20., 24.], [24., 28.], [28., 32.], [32., 36.], [36., 40.]]\n",
    "FB = np.array(FB)\n",
    "\n",
    "#argumaents for Chebyl II filtering\n",
    "# Nyquist frequency\n",
    "\n",
    "# min. attenuation in stop band\n",
    "gstop = 50\n",
    "# max. attenuation in passband\n",
    "gpass= 3 \n",
    "\n",
    "EEG_PERIOD = [[2.5,6]]\n",
    "FS = [250]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\tl_comp_csp_mi\\\\eval\\\\'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_root  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt_train 1\n",
      "A01E [0.97183099 0.85714286 0.8115942  0.85915493] 0.8749307438835914\n",
      "A02E [0.36619718 0.57746479 0.95652174 0.72222222] 0.6556014832959107\n",
      "A03E [0.68656716 1.         0.66176471 0.94117647] 0.8223770851624232\n",
      "A04E [0.45762712 0.87719298 0.72881356 0.66037736] 0.681002754728202\n",
      "A05E [0.87142857 0.93846154 0.11111111 0.33333333] 0.5635836385836386\n",
      "A06E [0.69811321 0.50909091 0.25925926 0.58490566] 0.5128422590686741\n",
      "A07E [0.85915493 0.95652174 0.81690141 0.93939394] 0.8929930041381358\n",
      "A08E [0.96969697 0.92647059 0.95652174 0.63235294] 0.8712605595597923\n",
      "A09E [0.93846154 0.76923077 0.8115942  0.76923077] 0.822129319955407\n",
      "pt_train 0.7\n",
      "A01E [0.92957746 0.85714286 0.85507246 0.67605634] 0.8294622809319686\n",
      "A02E [0.36619718 0.3943662  0.88405797 0.625     ] 0.5674053378240458\n",
      "A03E [0.65671642 1.         0.63235294 0.91176471] 0.8002085162423178\n",
      "A04E [0.40677966 0.78947368 0.6779661  0.79245283] 0.6666680692777676\n",
      "A05E [0.5        0.98461538 0.05555556 0.31884058] 0.46475287997027126\n",
      "A06E [0.79245283 0.63636364 0.2037037  0.35849057] 0.4977526840734388\n",
      "A07E [0.90140845 0.95652174 0.85915493 0.89393939] 0.9027561283378797\n",
      "A08E [0.93939394 0.91176471 0.97101449 0.58823529] 0.8526021080368906\n",
      "A09E [0.89230769 0.50769231 0.82608696 0.96923077] 0.7988294314381271\n",
      "pt_train 0.5\n",
      "A01E [0.94366197 0.91428571 0.82608696 0.63380282] 0.829459364884962\n",
      "A02E [0.49295775 0.26760563 0.79710145 0.38888889] 0.4866384296114853\n",
      "A03E [0.74626866 1.         0.72058824 0.89705882] 0.8409789288849868\n",
      "A04E [0.33898305 0.54385965 0.45762712 0.75471698] 0.5237966999366019\n",
      "A05E [0.61428571 0.87692308 0.         0.30434783] 0.44888915432393695\n",
      "A06E [0.75471698 0.27272727 0.09259259 0.37735849] 0.3743488342544946\n",
      "A07E [0.76056338 0.98550725 0.88732394 0.84848485] 0.8704698547013305\n",
      "A08E [0.87878788 0.95588235 0.92753623 0.64705882] 0.8523163217856312\n",
      "A09E [0.89230769 0.33846154 0.57971014 0.98461538] 0.6987736900780379\n",
      "pt_train 0.3\n",
      "A01E [0.71830986 0.9        0.69565217 0.77464789] 0.7721524800979792\n",
      "A02E [0.26760563 0.35211268 0.82608696 0.66666667] 0.5281179832618902\n",
      "A03E [0.6119403  0.97142857 0.51470588 0.91176471] 0.752459864542832\n",
      "A04E [0.23728814 0.57894737 0.50847458 0.60377358] 0.48212091629778\n",
      "A05E [0.64285714 0.32307692 0.27777778 0.43478261] 0.41962361310187396\n",
      "A06E [0.69811321 0.12727273 0.38888889 0.50943396] 0.4309271964932342\n",
      "A07E [0.63380282 0.65217391 0.61971831 0.89393939] 0.6999086084358589\n",
      "A08E [0.66666667 0.92647059 0.94202899 0.52941176] 0.7661445012787724\n",
      "A09E [0.83076923 0.30769231 0.50724638 0.98461538] 0.6575808249721293\n",
      "pt_train 0.1\n",
      "A01E [0.54929577 0.77142857 0.17391304 0.73239437] 0.5567579389379756\n",
      "A02E [0.4084507  0.1971831  0.55072464 0.41666667] 0.39325627679118186\n",
      "A03E [0.05970149 0.32857143 0.27941176 0.91176471] 0.39486234792424435\n",
      "A04E [0.27118644 0.38596491 0.         0.56603774] 0.3057972722019311\n",
      "A05E [0.1        0.72307692 0.19444444 0.23188406] 0.31235135637309547\n",
      "A06E [0.50943396 0.01818182 0.18518519 0.71698113] 0.35744552442665645\n",
      "A07E [0.6056338  0.33333333 0.35211268 0.86363636] 0.5386790439607341\n",
      "A08E [0.77272727 0.94117647 0.44927536 0.33823529] 0.625353599937999\n",
      "A09E [0.29230769 0.12307692 0.31884058 1.        ] 0.43355629877369006\n"
     ]
    }
   ],
   "source": [
    "for portion_train in [1,0.7,0.5,0.3,0.1]:\n",
    "    print ('pt_train', portion_train)\n",
    "\n",
    "    if to_save == 1:\n",
    "        filewrite = open(save_root + '4s_' + str(int(portion_train*100))+'_best_config_eval_acc_all_subjects.txt', 'w')\n",
    "        filewrite.write('')\n",
    "        filewrite.close()\n",
    "\n",
    "        filewrite = open(save_root + '4s_' + str(int(portion_train*100))+'_best_config_eval_acc_all_subjects.txt', 'a')\n",
    "        filewrite.write('subject, ')\n",
    "        for f in range (0, len(C_OVR)-1):\n",
    "            filewrite.write('class '+ str(C_OVR[f]+1) + ', ')\n",
    "        filewrite.write('class ' + str(C_OVR[-1]+1) + ', average'+ ', best_model_init_fold\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for subject in range (1,10):\n",
    "\n",
    "        filename = 'A0'+str(subject)+'E'\n",
    "        filename_save = filename\n",
    "        #print (filename_save)\n",
    "\n",
    "        eeg_period = EEG_PERIOD[0]\n",
    "        fs = FS[0]\n",
    "   \n",
    "        \n",
    "        for run_win in range (0,1):\n",
    "            if run_win == 0:\n",
    "                file_root_feature =  feature_root + filename_save[:-1] + '\\\\4s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                file_root_model = model_root + filename_save[:-1] + '\\\\4s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                #file_root_save = save_root + filename_save[:-1] + '\\\\4s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                #len_inp = 44\n",
    "            elif run_win == 1:\n",
    "                file_root_feature = feature_root + filename_save[:-1] + '\\\\2s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                file_root_model = model_root + filename_save[:-1] + '\\\\2s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                #file_root_save = save_root + filename_save[:-1] + '\\\\2s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                #len_inp = 25\n",
    "                \n",
    "            ###################################################################################################################\n",
    "                            #load best config\n",
    "            ###################################################################################################################\n",
    "            #load in best config line\n",
    "            config_file = open(file_root_model + '\\\\ANN\\\\best_config_val.txt', 'r')\n",
    "            config_log= config_file.readlines()\n",
    "            config_file.close()\n",
    "            for i in range (0,len(config_log)):\n",
    "                line  = config_log[(i + 1) * -1]\n",
    "                if '_act_fun_' in line: #and  line.split(' ')[0].split('_lambda_')[1] == '0':\n",
    "                    break\n",
    "\n",
    "            #extract best config values and make into dictionary\n",
    "            config = OrderedDict()\n",
    "            for hp_ind in range(0, len(hp_names)-1):\n",
    "                config[hp_names[hp_ind]] =  (line.split(hp_names[hp_ind] + '_')[1].split('_'+hp_names[hp_ind+1]+'_')[0])\n",
    "            config[hp_names[-1]] = line.split(hp_names[-1]+'_')[1].split(' ')[0]\n",
    "            \n",
    "            \n",
    "            ###################################################################################################################\n",
    "                    #load raw data\n",
    "            ###################################################################################################################\n",
    "            #load raw eeg and labels\n",
    "            EEG_extract_raw = pickle.load(open(raw_data_root\n",
    "                                                                    + filename_save + '.pickle', 'rb'),encoding='iso-8859-1')\n",
    "            #Class labels\n",
    "            LABELS_raw = pickle.load(open(raw_data_root\n",
    "                                                                + filename_save + \"_LABELS.pickle\", 'rb'), encoding='iso-8859-1')\n",
    "\n",
    "\n",
    "            LABELS = LABELS_raw - 1 #already in 1,2,3,4, the labels are. but we nned them to be likw 0,1,2,3\n",
    "       \n",
    "            #RUN THIS CODE ONLY ONCE, LABELS0 is the original labels, and LABELS will be changed in one-versus-rest strategy, later\n",
    "            LABELS0 = LABELS.copy()\n",
    "            \n",
    "            \n",
    "            ########################################################################################################################\n",
    "                                        #APPLY FILTER BANK\n",
    "            ########################################################################################################################\n",
    "            #Store Filter bank filtered raw EEG data, in the shape of num_filter_bank X num_trials X num_chanl X num_samples\n",
    "            #initiate empty matrix\n",
    "            EEG_filt_FB_L = np.empty( [len(FB), \n",
    "                                     np.shape(EEG_extract_raw)[0], np.shape(EEG_extract_raw)[1],np.shape(EEG_extract_raw)[2]] )\n",
    "\n",
    "            Nf = fs / 2.\n",
    "            for fb in range (0, len(FB)):\n",
    "                passband = FB[fb]\n",
    "                stopband = FB[fb] + np.array([-2., +2.])\n",
    "\n",
    "                EEG_filt_FB_L[fb] = filter_signal(EEG_extract_raw, passband, stopband, Nf, gpass, gstop)\n",
    "\n",
    "\n",
    "            EEG_filt_FB = EEG_filt_FB_L\n",
    "            \n",
    "            #trake only the MI 3.5 seconds\n",
    "            EEG_filt_FB_go = EEG_filt_FB[:,:,:,int(eeg_period[0]*fs):int(eeg_period[1]*fs)]\n",
    "            LABELS0_go = LABELS0.copy()\n",
    "            \n",
    "            \n",
    "            \n",
    "            ###########################################################################################################################\n",
    "    \n",
    "            pred_indi = []\n",
    "            ############################################################################################################################\n",
    "            OUT = 0\n",
    "            \n",
    "            best_mod_acc_prod = 0 #initialise best model average class acc\n",
    "            best_mod_kappa = -2\n",
    "            best_model = [0,0] #which model performs the best? model id, init = best_model[0], fold = best_model[1]\n",
    "    \n",
    "            for fold in range (0, k_fold):\n",
    "                #print ('fold', fold)\n",
    "\n",
    "                pred_indi.append([])\n",
    "                \n",
    "                for c_ovr in C_OVR:\n",
    "                    #print (c_ovr)\n",
    "                    #load in csp filters and mutual informtaion ranked indicies\n",
    "                    W_B = pickle.load(open( file_root_feature +'\\\\W_B_fold_' + str(fold) + \n",
    "                                               '_c_ovr_' + str(c_ovr) + '_lambda_' + str(float(config['_lambda'])) + \n",
    "                                               \".pickle\", 'rb'))\n",
    "\n",
    "\n",
    "                    FB_FILTER_IND = pickle.load(open( file_root_feature +  '\\\\FB_FILTER_IND_fold_' + str(fold) + \n",
    "                                               '_c_ovr_' + str(c_ovr) + '_lambda_' + str(float(config['_lambda'])) + \n",
    "                                               \".pickle\", 'rb'))\n",
    "\n",
    "                    #find the selected csp filters indicies\n",
    "                    FB_FILTER_IND_slt = find_selected_csp_filters(Ns, m, FB_FILTER_IND)\n",
    "\n",
    "                    #construct selected csp filters, W_B_slt has shape (2*Ns, num_chls), (8,22) for example\n",
    "                    W_B_slt = W_B[FB_FILTER_IND_slt[:,0], :, FB_FILTER_IND_slt[:,1]]\n",
    "\n",
    "                    EEG_FB_slt = EEG_filt_FB_go[FB_FILTER_IND_slt[:,0],:]\n",
    "\n",
    "                    #transform into z space, then take the hilbert envelope of the transformed signal\n",
    "                    Z_env = calc_z_features(W_B_slt, EEG_FB_slt, Ns, down_sample_step)\n",
    "\n",
    "                    #concatenate all classes\n",
    "                    if c_ovr == C_OVR[0]:\n",
    "                        Z_all_eval = Z_env\n",
    "                    else:\n",
    "                        Z_all_eval = np.concatenate((Z_all_eval, Z_env), axis = 0)\n",
    "\n",
    "                #reshape into ANN input size        \n",
    "                Z_all_eval = np.transpose(Z_all_eval, [1,0,2])\n",
    "                X_eval = np.reshape(Z_all_eval, [np.shape(Z_all_eval)[0], 1, np.shape(Z_all_eval)[1], np.shape(Z_all_eval)[2]])\n",
    "                X_eval = torch.from_numpy(X_eval).float()\n",
    "                \n",
    "                #initilize ANN model\n",
    "                model = Model_current(chn_inp = X_eval.size()[-2], len_inp = X_eval.size()[-1], nf = int(config['nf']), ks = int(config['ks']) , \n",
    "                                  stride = int(config['stride']), act_f = config['act_fun'], nfc = int(config['nfc']))\n",
    "                \n",
    "                for n_inits in range (0, num_inits):\n",
    "                    save_path = file_root_model + '\\\\ANN\\\\model_config_'+ line.split(' ')[0] + '_n_inits_'+ str(n_inits) +'_fold_' + str(fold) + '.pt'\n",
    "                    model.load_state_dict(torch.load(save_path))\n",
    "                    model.eval()\n",
    "\n",
    "                    #predictoin, sum up the output (probability of being class) predicted at each fold, tehn the class with the max probability if the class prediction\n",
    "                    out = model(X_eval)\n",
    "                    OUT = OUT + out\n",
    "\n",
    "                    #print out class precition at each fold\n",
    "                    pred = torch.argmax(out, dim = 1).numpy()\n",
    "                    #print (str(n_inits), np.average(calc_class_acc(pred, LABELS0, C_OVR)))\n",
    "                    if cohen_kappa_score(LABELS0, pred) > best_mod_kappa:\n",
    "                        best_model = [n_inits, fold]\n",
    "                        best_mod_acc_prod = np.average(calc_class_acc(pred, LABELS0, C_OVR))\n",
    "                        best_mod_kappa = cohen_kappa_score(LABELS0, pred)\n",
    "\n",
    "                    #pred_indi[fold].append(cohen_kappa_score(LABELS0, pred))\n",
    "                    \n",
    "                    \n",
    "            #final prediciotn using all trained ANNs   \n",
    "            PRED = torch.argmax(OUT, dim = 1).numpy()\n",
    "            acc_c = calc_class_acc(PRED, LABELS0, C_OVR)\n",
    "            print(filename, acc_c, np.average(acc_c))\n",
    "            kappa = cohen_kappa_score(LABELS0, PRED)\n",
    "            \n",
    "            if to_save == 1:\n",
    "                filewrite.write(str(subject) + ', ')\n",
    "\n",
    "                for a in acc_c:\n",
    "                    filewrite.write(str(round(a*100,2)) + ', ')\n",
    "                filewrite.write(str(round(np.average(acc_c)*100, 2)) +' '+'('+str(round(kappa, 3))+')' +', ' + str(best_model[0])+'_'+str(best_model[1]) + '_'+ str(best_mod_acc_prod) + '(' + str(best_mod_kappa) + ')'  +'\\n')\n",
    "                \n",
    "                \n",
    "    if to_save == 1:\n",
    "        filewrite.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'83.33 (0.777), 3_1_0.543014730897462(-2)'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mod_kappa = -2\n",
    "str(round(np.average(acc_c)*100, 2)) +' '+'('+str(round(kappa, 3))+')' +', ' + str(best_model[0])+'_'+str(best_model[1]) + '_'+ str(best_mod_acc_prod) + '(' + str(best_mod_kappa) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'88.24 (0.843), 0_0'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mod_acc_prod = 0\n",
    "best_model = [0,0]\n",
    "str(round(np.average(acc_c)*100, 2)) +' '+'('+str(round(kappa, 3))+')' +', ' + str(best_model[0])+'_'+str(best_model[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-2defb46115bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cl' is not defined"
     ]
    }
   ],
   "source": [
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27137472723665934, 0.7477779721809116)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(calc_class_acc(pred, LABELS0, C_OVR)), np.average(calc_class_acc(pred, LABELS0, C_OVR))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97183099, 0.54285714, 0.91304348, 0.56338028])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_class_acc(pred, LABELS0, C_OVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['_lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\gold_stand\\\\A01\\\\4s\\\\pt_100'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_root_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 281, 22, 875), (281,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(EEG_filt_FB_go), np.shape(LABELS0_go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\gold_stand\\\\A01\\\\4s\\\\pt_100'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_root_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
