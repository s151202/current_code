{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('D:\\Diamond\\code')\n",
    "from csp_james_2 import *\n",
    "\n",
    "sys.path.append('D:\\Diamond\\code')\n",
    "from thesis_funcs_19_03 import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import csv\n",
    "from random import randint\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_root  = 'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\tl_comp_csp_mi\\\\'\n",
    "config_root= 'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\configs\\\\' #fixed\n",
    "raw_data_root = 'E:\\\\Diamond\\\\bci_iv\\\\DATA\\\\2a\\\\extract_raw\\\\' #fixed\n",
    "\n",
    "\n",
    "k_fold = 10\n",
    "\n",
    "\n",
    "# initialize csp\n",
    "m = 2# m is Nw in the paper \"learning temporal information for brain-copmuter interface, Sakhavi et.al\"\n",
    "n_components = 2 * m  # pick some components\n",
    "down_sample_step = 20 #Hilbert evelope\n",
    "# select Ns pairs of csp filters\n",
    "Ns = 4\n",
    "\n",
    "CLASSES =[0,1]\n",
    "\n",
    "C_OVR = [0,1,2,3]\n",
    "\n",
    "balance_classes = 1\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "                                            # DEFINE FILTER BANK\n",
    "########################################################################################################################\n",
    "#Filter Bank\n",
    "FB = [[4., 8.], [8., 12.], [12., 16.], [16., 20.], [20., 24.], [24., 28.], [28., 32.], [32., 36.], [36., 40.]]\n",
    "FB = np.array(FB)\n",
    "\n",
    "#argumaents for Chebyl II filtering\n",
    "# Nyquist frequency\n",
    "\n",
    "# min. attenuation in stop band\n",
    "gstop = 50\n",
    "# max. attenuation in passband\n",
    "gpass= 3 \n",
    "\n",
    "\n",
    "EEG_PERIOD = [[2.5,6]]\n",
    "FS = [250]\n",
    "eeg_period = EEG_PERIOD[0]\n",
    "fs = FS[0]\n",
    "Nf = fs/2.0\n",
    "\n",
    "\n",
    "to_center_matrix = 0\n",
    "calc_kl_d = 0\n",
    "calc_mi_discrim  =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read _lambda values\n",
    "with open(config_root +'_lambda_config.csv', mode = 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    for row in csv_reader:\n",
    "        _lambda_list_str = row[1:]\n",
    "csv_file.close()        \n",
    "\n",
    "#create _lambda value in list\n",
    "_lambda_list = []\n",
    "for i in _lambda_list_str:\n",
    "    _lambda_list.append(float(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.2, 0.4, 0.6, 0.8, 1.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_lambda_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CALCULATE COVARIENCE MATRICES FOR ALL SUBJECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#t0  = datetime.datetime.now()\n",
    "for subject in range(0,0):\n",
    "    print (subject)\n",
    "    filename_T = 'A0'+str(subject)+'T'\n",
    "    filename_E = 'A0'+str(subject)+'E'\n",
    "    #ilename_save = filename\n",
    "    #rint (filename_save)\n",
    "    \n",
    "    file_root  = save_root + 'A0'+str(subject) + '\\\\4s\\\\'\n",
    "\n",
    "    ########################################################################################################################\n",
    "                                                        #LOAD DATA\n",
    "    ########################################################################################################################\n",
    "    #load raw eeg and labels\n",
    "    EEG_extract_raw_T = pickle.load(open('E://Diamond//bci_iv//DATA//2a//extract_raw//' \n",
    "                                                            + filename_T + '.pickle', 'rb'),encoding='iso-8859-1')\n",
    "    #Class labels\n",
    "    LABELS_raw_T = pickle.load(open(\"E://Diamond//bci_iv//DATA//2a//extract_raw//\" \n",
    "                                                        + filename_T + \"_LABELS.pickle\", 'rb'), encoding='iso-8859-1')\n",
    "\n",
    "\n",
    "    EEG_extract_raw_E = pickle.load(open('E://Diamond//bci_iv//DATA//2a//extract_raw//' \n",
    "                                                            + filename_E + '.pickle', 'rb'),encoding='iso-8859-1')\n",
    "    #Class labels\n",
    "    LABELS_raw_E = pickle.load(open(\"E://Diamond//bci_iv//DATA//2a//extract_raw//\" \n",
    "                                                        + filename_E + \"_LABELS.pickle\", 'rb'), encoding='iso-8859-1')\n",
    "\n",
    "    ##concatenate training trials and evaluation trails into composite matrix\n",
    "    EEG_extract_raw = np.concatenate((EEG_extract_raw_T,EEG_extract_raw_E),axis = 0)\n",
    "    LABELS_raw = np.concatenate((LABELS_raw_T,LABELS_raw_E),axis = 0)\n",
    "\n",
    "\n",
    "    LABELS = LABELS_raw - 1 #already in 1,2,3,4, the labels are. but we nned them to be likw 0,1,2,3\n",
    "\n",
    "    #RUN THIS CODE ONLY ONCE, LABELS0 is the original labels, and LABELS will be changed in one-versus-rest strategy, later\n",
    "    LABELS0 = LABELS.copy()\n",
    "\n",
    "    ########################################################################################################################\n",
    "                                        #APPLY FILTER BANK\n",
    "    ########################################################################################################################\n",
    "    #Store Filter bank filtered raw EEG data, in the shape of num_filter_bank X num_trials X num_chanl X num_samples\n",
    "    #initiate empty matrix\n",
    "    EEG_filt_FB_L = np.empty( [len(FB), \n",
    "                             np.shape(EEG_extract_raw)[0], np.shape(EEG_extract_raw)[1],np.shape(EEG_extract_raw)[2]] )\n",
    "\n",
    "    for fb in range (0, len(FB)):\n",
    "        passband = FB[fb]\n",
    "        stopband = FB[fb] + np.array([-2., +2.])\n",
    "\n",
    "        EEG_filt_FB_L[fb] = filter_signal(EEG_extract_raw, passband, stopband, Nf, gpass, gstop)\n",
    "\n",
    "        \n",
    "    EEG_filt_FB = EEG_filt_FB_L\n",
    "    \n",
    "    if center_matrix == 1:\n",
    "        EEG_filt_FB = center_matrix(EEG_filt_FB)\n",
    "    \n",
    "\n",
    "    #trake only the MI 3.5 seconds\n",
    "    EEG_filt_FB_go = EEG_filt_FB[:,:,:,int(eeg_period[0]*fs):int(eeg_period[1]*fs)]\n",
    "    LABELS0_go = LABELS0.copy()\n",
    "\n",
    "   \n",
    "    ########################################################################################################################\n",
    "\n",
    "    \n",
    "    balance_classes = 1\n",
    "        \n",
    "    Covs = np.zeros((len(FB), len(C_OVR), 2, np.shape(EEG_filt_FB_go)[2], np.shape(EEG_filt_FB_go)[2]))\n",
    "    for fb in range (0, len(FB)):\n",
    "        for c_ovr in C_OVR:\n",
    "            \n",
    "            if balance_classes == 1:\n",
    "                c_indx = make_ovr_sets_strat(c_ovr, C_OVR, LABELS0_go)\n",
    "            else:\n",
    "                c_indx = np.array(np.arange(0,len(LABELS0_go)))\n",
    "            LABELS0_go_c_ovr = make_ovr_01_labels(LABELS0_go[c_indx].copy(), c_ovr)\n",
    "            covs = covs_classes(_classes = [0,1], n_ch = np.shape(EEG_filt_FB_go)[2], X = EEG_filt_FB_go[fb][c_indx], y = LABELS0_go_c_ovr)\n",
    "            Covs[fb][c_ovr] = covs\n",
    "    if to_save == 1:\n",
    "        pickle.dump(Covs, open(file_root + 'Covs.pickle', 'wb'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\tl_comp_csp_mi\\\\'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "portion = 0.7\n",
    "portion_train = str(int(portion*100)) #in the old versions of code portion_train is cv_train\n",
    "cv_train_size = 0.7 #cv_train_size if the actually cv split\n",
    "\n",
    "\n",
    "\n",
    "for k in range (1, 10):\n",
    "    print (k)\n",
    "    filename_T = 'A0'+str(k)+'T'\n",
    "    file_root  = save_root + 'A0'+str(k) + '\\\\4s\\\\'\n",
    "    \n",
    "    k_file_root = file_root+'pt_'+ portion_train\n",
    "    \n",
    "    #set load_idx to 0 if we want to create new and overwirite old T_IND files\n",
    "    load_idx = 0 # 0 to create and save new sets of train and test index, 1 to load already created indices\n",
    "    COVS_AL_FD,  EEG_filt_FB_go, LABELS0_go, TRAIN_IDX, TEST_IDX, Train_idx = calc_k_covs_all_fold_current(filename_T, raw_data_root, \n",
    "                                                                                                            portion, k_file_root, \n",
    "                                                                                                            balance_classes, \n",
    "                                                                                                   FB,  gpass, gstop, fs, eeg_period, \n",
    "                                                                                                   k_fold, C_OVR, load_idx = load_idx, \n",
    "                                                                                                   cv_train_size = cv_train_size, \n",
    "                                                                                                 to_center_matrix = to_center_matrix)\n",
    "     \n",
    "    if to_save == 1 and load_idx == 0:\n",
    "        pickle.dump(TRAIN_IDX , open(file_root +'pt_'+ portion_train + '\\\\TRAIN_IDX' + \".pickle\", \"wb\" ) )\n",
    "\n",
    "        pickle.dump(TEST_IDX , open(file_root +'pt_'+ portion_train + '\\\\TEST_IDX' + \".pickle\", \"wb\" ) )\n",
    "\n",
    "        pickle.dump(LABELS0_go , open(file_root +'pt_'+ portion_train + '\\\\LABELS0_go' + \".pickle\", \"wb\" ) )\n",
    "    \n",
    "    MI_score_write = open(file_root+ '\\\\pt_' + portion_train + '\\\\MI_score.txt', \"w\")\n",
    "    MI_score_write.write('')\n",
    "    MI_score_write.close()\n",
    "    MI_score_vals_write = open(file_root+ '\\\\pt_' + portion_train + '\\\\MI_score_vals.txt', \"w\")\n",
    "    MI_score_vals_write.write('')\n",
    "    MI_score_vals_write.close()\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    for fold in range (0, k_fold):\n",
    "        Covs_k = COVS_AL_FD[fold]\n",
    "        \n",
    "        MI_score_write = open(file_root + '\\\\pt_' + portion_train + '\\\\MI_score.txt', \"a\")\n",
    "        MI_score_write.write('fold,'+str(fold)+ '\\n')\n",
    "        MI_score_vals_write = open(file_root + '\\\\pt_' + portion_train + '\\\\MI_score_vals.txt', \"a\")\n",
    "        MI_score_vals_write.write('fold,'+str(fold)+ '\\n')\n",
    "        \n",
    "        for _lambda in _lambda_list:\n",
    "            \n",
    "            for c_ovr in C_OVR:\n",
    "                W_B = []\n",
    "                for i in range (0, len(FB)):\n",
    "                    W_B.append([])\n",
    "                    \n",
    "                \n",
    "                train_idx = Train_idx[fold][c_ovr]\n",
    "                EEG_train = EEG_filt_FB_go[:, train_idx, :]    \n",
    "                LABELS_train = LABELS0_go[train_idx]\n",
    "                LABELS_train = make_ovr_01_labels(LABELS_train, c_ovr)\n",
    "                \n",
    "                V= [] \n",
    "                for tr in range (0, len(train_idx)):\n",
    "                    V.append([])\n",
    "                \n",
    "                ########### how discriminative does subject l perform on subject k's data (Mutual information) ######### \n",
    "                for fb in range (0, len(FB)):\n",
    "                    MI_SCORE = OrderedDict()\n",
    "\n",
    "                    for l in range (1, 10):\n",
    "                        if l != k:\n",
    "                            #print (l)\n",
    "                            V1 = []\n",
    "                            for tr in range (0, len(train_idx)):\n",
    "                                V1.append([]) \n",
    "                            \n",
    "                            \n",
    "                            Covs_l = pickle.load(open(save_root + 'A0'+str(l) + '\\\\4s\\\\' + 'Covs.pickle', 'rb'))\n",
    "\n",
    "                            C_l = Covs_l[fb, c_ovr]\n",
    "\n",
    "                            eigen_vectors_sorted, eigen_values = calc_sort_eigenvectors(C_l)\n",
    "                            W_b_ = np.concatenate ( [eigen_vectors_sorted[:, 0:int(m)],  eigen_vectors_sorted[:, -int(m):]], axis = 1)\n",
    "                            \n",
    "                            for tr in range (0, len(train_idx)):\n",
    "                                eeg = EEG_train[fb, tr, :]\n",
    "\n",
    "                                #calculate features\n",
    "                                v_bi = csp_features(W_b_, m, eeg)\n",
    "\n",
    "                                #contruct feature matrix\n",
    "                                V1[tr].append(v_bi)\n",
    "                                \n",
    "                            V1 = np.array(V1)\n",
    "                            V1 = V1.reshape([np.shape(V1)[0], np.shape(V1)[1]*np.shape(V1)[2]]) \n",
    "                            F1 = np.transpose(V1)\n",
    "                            ####CALCULATE MUTUAL INFORMATION FOR THE FEATURES\n",
    "                            I_fj = calc_MI(FB[fb:fb+1], m, CLASSES, LABELS_train, F1)\n",
    "                            I_fj_sorted = np.argsort(I_fj)[::-1]\n",
    "\n",
    "                            mi_score = np.average(I_fj[I_fj_sorted[0:2*Ns]])\n",
    "\n",
    "                            MI_SCORE[str(l)] = mi_score\n",
    "                    \n",
    "                    MI_SCORE_vals = np.array(list(MI_SCORE.values()))\n",
    "                    range2 = [1,10]\n",
    "                    \n",
    "                    for key in MI_SCORE.keys():\n",
    "                        MI_SCORE[key] = ((MI_SCORE[key] - min(MI_SCORE_vals)) / (max(MI_SCORE_vals) - min(MI_SCORE_vals))) * (range2[1] - range2[0]) + range2[0]\n",
    "                    \n",
    "                    \n",
    "                    if _lambda == _lambda_list[0]:\n",
    "                        count = 0\n",
    "                        for i in MI_SCORE.keys():\n",
    "                            MI_score_write.write ('sub,' + i + ',fold,' + str(fold) + ',c_ovr,' + str(c_ovr) + ',fb,' + str(fb) + ',mi_score,' + str(MI_SCORE[i]) + '\\n')\n",
    "                            MI_score_vals_write.write ('sub,' + i + ',fold,' + str(fold) + ',c_ovr,' + str(c_ovr) + ',fb,' + str(fb) + ',mi_score,' + str(MI_SCORE_vals[count])+ '\\n')\n",
    "                            count += 1\n",
    "                    \n",
    "                    #scale wieghts\n",
    "                    weights = OrderedDict()\n",
    "                    for key in MI_SCORE.keys():\n",
    "                        weights[key] = MI_SCORE[key] / np.sum(np.array(list(MI_SCORE.values())))\n",
    "                    \n",
    "                    \n",
    "                    sec_term = 0\n",
    "                    for j in range (1,10):\n",
    "                        if j != k:\n",
    "                            Covs_j = pickle.load(open(save_root + 'A0'+str(j) + '\\\\4s\\\\' + 'Covs.pickle', 'rb'))\n",
    "                            sec_term += weights[str(j)] * Covs_j[fb, c_ovr]\n",
    "\n",
    "                            \n",
    "                    ######################################################################################\n",
    "                    ##### COMPOSITE CSP USING MUTUAL INFORMATION, transfer learning weighted by lambda\n",
    "                    C_ck = (1-_lambda)*Covs_k[fb, c_ovr] + _lambda*sec_term \n",
    "                    \n",
    "                    eigen_vectors_sorted, eigen_values = calc_sort_eigenvectors(C_ck)\n",
    "                    W_b_ = np.concatenate ( [eigen_vectors_sorted[:, 0:int(m)],  eigen_vectors_sorted[:, -int(m):]], axis = 1)\n",
    "                    W_B[fb].append(W_b_)\n",
    "                    \n",
    "                    for tr in range (0, len(train_idx)):\n",
    "                        eeg = EEG_train[fb, tr, :]\n",
    "\n",
    "                        #calculate features\n",
    "                        v_bi = csp_features(W_b_, m, eeg)\n",
    "\n",
    "                        #contruct feature matrix\n",
    "                        V[tr].append(v_bi)\n",
    "                        \n",
    "                V = np.array(V)\n",
    "                V = V.reshape([np.shape(V)[0], np.shape(V)[1]*np.shape(V)[2]]) \n",
    "                W_B = np.array(W_B).squeeze()\n",
    "\n",
    "                #follow MIBIF Algorithm in bci_iv_fbcsp paper\n",
    "                F = np.transpose(V)  \n",
    "\n",
    "                ####CALCULATE MUTUAL INFORMATION FOR THE FEATURES\n",
    "                I_fj = calc_MI(FB, m, CLASSES, LABELS_train, F)\n",
    "\n",
    "                ####SORT FEATURES ACCORDING TO MUTAUL INFORMATION\n",
    "                # I_fj_sorted is the indices of features ranked by decending mutal information, in shape (num_features, );\n",
    "                #where num_features = 2* m * num_FB\n",
    "                I_fj_sorted = np.argsort(I_fj)[::-1]\n",
    "\n",
    "\n",
    "                #the filter bank indices from which the features come from, in shape (num_features, )\n",
    "                FB_IND = np.floor(I_fj_sorted/(2*m)).astype(int)\n",
    "                #the filter channel (csp.eigen_vectors_sorted column) indiceis from which the features come from, in shape (num_features, )\n",
    "                FILTER_IND = (I_fj_sorted) - FB_IND * (2*m)\n",
    "\n",
    "                #combine the filterbank indicies and the CSP filter indicies, \n",
    "                #first column tells which filter bank the feature came from, \n",
    "                #second column tells which csp filter channel the feature came from\n",
    "                FB_FILTER_IND = np.array(list(zip(FB_IND, FILTER_IND)))\n",
    "                \n",
    "                if to_save == 1:\n",
    "                    pickle.dump( W_B, open(file_root + 'pt_' + portion_train\n",
    "                                                    + '\\\\W_B_fold_' + str(fold) + \n",
    "                                           '_c_ovr_' + str(c_ovr) + '_lambda_' + str(_lambda) +\n",
    "                                           \".pickle\", \"wb\" ) )\n",
    "\n",
    "                    pickle.dump( FB_FILTER_IND, open(file_root + 'pt_' + portion_train + '\\\\FB_FILTER_IND_fold_' + str(fold) + \n",
    "                                           '_c_ovr_' + str(c_ovr) + '_lambda_' + str(_lambda) +\n",
    "                                           \".pickle\", \"wb\" ) )\n",
    "                    \n",
    "                \n",
    "    ########################################################################################################################\n",
    "\n",
    "    for fold in range (0, k_fold):\n",
    "        #print ('fold', fold)\n",
    "        for _lambda in _lambda_list:\n",
    "            for c_ovr in C_OVR:\n",
    "                \n",
    "                #load in csp filters and mutual informtaion ranked indicies\n",
    "                W_B = pickle.load(open( file_root + 'pt_' + portion_train\n",
    "                                                    + '\\\\W_B_fold_' + str(fold) + \n",
    "                                           '_c_ovr_' + str(c_ovr) + '_lambda_' + str(_lambda) + \n",
    "                                           \".pickle\", 'rb'))\n",
    "\n",
    "\n",
    "                FB_FILTER_IND = pickle.load(open( file_root + 'pt_' + portion_train\n",
    "                                                    + '\\\\FB_FILTER_IND_fold_' + str(fold) + \n",
    "                                           '_c_ovr_' + str(c_ovr) + '_lambda_' + str(_lambda) + \n",
    "                                           \".pickle\", 'rb'))\n",
    "                \n",
    "                \n",
    "                #find the selected csp filters indicies\n",
    "                FB_FILTER_IND_slt = find_selected_csp_filters(Ns, m, FB_FILTER_IND)\n",
    "\n",
    "                #construct selected csp filters, W_B_slt has shape (2*Ns, num_chls), (8,22) for example\n",
    "                W_B_slt = W_B[FB_FILTER_IND_slt[:,0], :, FB_FILTER_IND_slt[:,1]]\n",
    "\n",
    "\n",
    "\n",
    "                #load in training eeg signals and testing EEG\n",
    "                train_idx = TRAIN_IDX[fold]\n",
    "                test_idx = TEST_IDX[fold]\n",
    "                EEG_train_FB = EEG_filt_FB_go[:,train_idx,:]\n",
    "                EEG_test_FB = EEG_filt_FB_go[:,test_idx,:]\n",
    "                #pick only the eeg signals filtered by selected filter banks\n",
    "                EEG_train_FB_slt = EEG_train_FB[FB_FILTER_IND_slt[:,0], :]\n",
    "                EEG_test_FB_slt = EEG_test_FB[FB_FILTER_IND_slt[:,0], :]\n",
    "\n",
    "                #transform into z space, then take the hilbert envelope of the transformed signal\n",
    "                Z_env_train = calc_z_features(W_B_slt, EEG_train_FB_slt, Ns, down_sample_step)\n",
    "                Z_env_test = calc_z_features(W_B_slt, EEG_test_FB_slt, Ns, down_sample_step)\n",
    "\n",
    "                #concatenate all classes\n",
    "                if c_ovr == C_OVR[0]:\n",
    "                    Z_all_classes_train = Z_env_train\n",
    "                    Z_all_classes_test = Z_env_test\n",
    "                else:\n",
    "                    Z_all_classes_train = np.concatenate((Z_all_classes_train, Z_env_train), axis = 0)\n",
    "                    Z_all_classes_test = np.concatenate((Z_all_classes_test, Z_env_test), axis = 0)\n",
    "                    \n",
    "            #trasnpose into shape (num_trials, num_features, sample points)\n",
    "            Z_all_classes_train = np.transpose(Z_all_classes_train, [1,0,2])\n",
    "            Z_all_classes_test = np.transpose(Z_all_classes_test, [1,0,2])\n",
    "\n",
    "            #save the Z space hilbert envelop signals\n",
    "            if to_save == 1:\n",
    "                pickle.dump( Z_all_classes_train, open(file_root +'pt_' + portion_train\n",
    "                                                    + '\\\\Z_all_classes_train_fold_' + str(fold) + '_lambda_' + str(_lambda) + \".pickle\", \"wb\" ) )\n",
    "\n",
    "                pickle.dump( Z_all_classes_test, open(file_root +'pt_' + portion_train\n",
    "                                                    + '\\\\Z_all_classes_test_fold_' + str(fold) + '_lambda_' + str(_lambda) + \".pickle\", \"wb\" ) )\n",
    "\n",
    "\n",
    "\n",
    "    if to_save == 1:\n",
    "        MI_score_write.close()\n",
    "        MI_score_vals_write.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-13.18607994, -14.71548466, -14.51332725, -14.66271145,\n",
       "       -13.89988831, -14.20405894, -15.12390236, -13.65705057])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI_SCORE_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "print (portion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-77.3416249 , -76.1576916 , -79.33752962, -75.94727417,\n",
       "       -78.76682398, -74.52494616, -78.31712559, -78.77128242])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI_SCORE_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub,1,fold,9,c_ovr,3,fb,8,mi_score,4.732536297144877\n",
      "sub,1,fold,9,c_ovr,3,fb,8,mi_score,-77.34162489984658\n",
      "sub,2,fold,9,c_ovr,3,fb,8,mi_score,6.946606932573529\n",
      "sub,2,fold,9,c_ovr,3,fb,8,mi_score,-76.1576915977171\n",
      "sub,3,fold,9,c_ovr,3,fb,8,mi_score,1.0\n",
      "sub,3,fold,9,c_ovr,3,fb,8,mi_score,-79.33752961620235\n",
      "sub,4,fold,9,c_ovr,3,fb,8,mi_score,7.340108024991786\n",
      "sub,4,fold,9,c_ovr,3,fb,8,mi_score,-75.94727417006891\n",
      "sub,5,fold,9,c_ovr,3,fb,8,mi_score,2.067275149382838\n",
      "sub,5,fold,9,c_ovr,3,fb,8,mi_score,-78.7668239794127\n",
      "sub,6,fold,9,c_ovr,3,fb,8,mi_score,10.0\n",
      "sub,6,fold,9,c_ovr,3,fb,8,mi_score,-74.52494615627928\n",
      "sub,7,fold,9,c_ovr,3,fb,8,mi_score,2.9082549572545835\n",
      "sub,7,fold,9,c_ovr,3,fb,8,mi_score,-78.31712558902461\n",
      "sub,8,fold,9,c_ovr,3,fb,8,mi_score,2.0589374355800403\n",
      "sub,8,fold,9,c_ovr,3,fb,8,mi_score,-78.77128241758392\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in MI_SCORE.keys():\n",
    "    MI_score.write ('sub,' + i + ',fold,' + str(fold) + ',c_ovr,' + str(c_ovr) + ',fb,' + str(fb) + ',mi_score,' + str(MI_SCORE[i]) + '\\n')\n",
    "    MI_score_vals.write ('sub,' + i + ',fold,' + str(fold) + ',c_ovr,' + str(c_ovr) + ',fb,' + str(fb) + ',mi_score,' + str(MI_SCORE_vals[count])+ '\\n')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4678401804893484"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6.946606932573529/4.732536297144877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12491293, 0.12300078, 0.12813647, 0.12266094, 0.12721474,\n",
       "       0.12036377, 0.12648844, 0.12722194])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umm = MI_SCORE_vals\n",
    "umm/np.sum(umm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-77.3416249 , -76.1576916 , -79.33752962, -75.94727417,\n",
       "       -78.76682398, -74.52494616, -78.31712559, -78.77128242])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI_SCORE_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0155458138912392"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-77.3416249/-76.1576916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\tl_comp_csp_mi\\\\A00\\\\4s\\\\'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_root + 'A0'+str(0) + '\\\\4s\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goog\n"
     ]
    }
   ],
   "source": [
    "print('goog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
