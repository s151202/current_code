{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('D:\\Diamond\\code')\n",
    "from csp_james_2 import *\n",
    "\n",
    "sys.path.append('D:\\Diamond\\code')\n",
    "from thesis_funcs_19_03 import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import csv\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = 10\n",
    "\n",
    "FS= [250]\n",
    "num_epoch = 300\n",
    "\n",
    "meth = 'tl_comp_csp_mi' #gold_standï¼Œtl_comp_csp_kld , tl_comp_csp_mi\n",
    "config_root= 'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\configs\\\\'\n",
    "feature_root = 'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\' + meth + '\\\\'\n",
    "save_root = feature_root\n",
    "\n",
    "\n",
    "if meth == 'gold_stand':\n",
    "    tl =  0 # tl = 1 if use lambda i.e. transfer learning is activated, if tl = 0, the lambda = 0, i.e. gold standard - no transfer learning applied\n",
    "elif meth == 'tl_comp_csp_kld' or meth == 'tl_comp_csp_mi':\n",
    "    tl = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "                #load best config\n",
    "###################################################################################################################\n",
    "#load in cv config grid\n",
    "hp_names  =[] #all the hyper-parameter names to be validated\n",
    "cv_config = []\n",
    "\n",
    "\n",
    "\n",
    "with open(config_root +'cv_config.csv', mode = 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    for row in csv_reader:\n",
    "        hp_names.append((row[0]).strip())\n",
    "        cv_config.append(row)\n",
    "\n",
    "#apppending _lambda config into cv_config of NN model     \n",
    "with open(config_root +'_lambda_config.csv', mode = 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    for row in csv_reader:\n",
    "        hp_names.append((row[0]).strip())\n",
    "\n",
    "        if tl == 0:\n",
    "            cv_config.append(row[0:2])\n",
    "        elif tl == 1:\n",
    "            cv_config.append(row)\n",
    "        \n",
    "        \n",
    "#strip away extra white spaces\n",
    "for row in range (0, len(cv_config)):\n",
    "    for i in range (0, len(cv_config[row])):\n",
    "        cv_config[row][i] = cv_config[row][i].strip()    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['act_fun', 'leaky_relu'],\n",
       " ['nf', '8', '16', '32'],\n",
       " ['ks', '4', '8', '16'],\n",
       " ['stride', '2'],\n",
       " ['nfc', '20', '60', '180'],\n",
       " ['optim', 'ADAM_0.001'],\n",
       " ['_lambda', '0', '0.2', '0.4', '0.6', '0.8', '1']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A06T\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Diamond\\code\\thesis_funcs_19_03.py:1334: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = nnF.softmax(self.fc3(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "0.5\n",
      "0.3\n",
      "0.1\n",
      "A07T\n",
      "1\n",
      "0.7\n",
      "0.5\n",
      "0.3\n",
      "0.1\n",
      "A08T\n",
      "1\n",
      "0.7\n",
      "0.5\n",
      "0.3\n",
      "0.1\n",
      "A09T\n",
      "1\n",
      "0.7\n",
      "0.5\n",
      "0.3\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "num_inits = 5\n",
    "for subject in range (6,10):\n",
    "\n",
    "    filename = 'A0'+str(subject)+'T'\n",
    "    filename_save = filename\n",
    "    print (filename_save)\n",
    "    \n",
    "    \n",
    "    for portion_train in [1,0.7,0.5,0.3,0.1]:    \n",
    "        #print ('cv_train_size', cv_train_size)\n",
    "        print (portion_train)\n",
    "        \n",
    "        for run_win in range (0,1):\n",
    "            if run_win == 0:\n",
    "                file_root_feature =  feature_root + filename_save[:-1] + '\\\\4s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                file_root_save = save_root + filename_save[:-1] + '\\\\4s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                #len_inp = 44\n",
    "            elif run_win == 1:\n",
    "                file_root_feature = feature_root + filename_save + '\\\\2s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                file_root_save = save_root + filename_save[:-1] + '\\\\2s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                #len_inp = 25\n",
    "                \n",
    "            \n",
    "            LABELS0_go = pickle.load(open(file_root_feature + '\\\\LABELS0_go.pickle', 'rb'))\n",
    "            TRAIN_IDX = pickle.load(open(file_root_feature  + '\\\\TRAIN_IDX.pickle', 'rb'))\n",
    "            TEST_IDX = pickle.load(open(file_root_feature + '\\\\TEST_IDX.pickle', 'rb'))  \n",
    "            \n",
    "            \n",
    "            \n",
    "            batch_size = np.shape(TRAIN_IDX)[-1]\n",
    "            #batch_size = 50\n",
    "            \n",
    "            \n",
    "            if to_save == 1:\n",
    "                filewrite = open(file_root_save + '\\\\ANN\\\\best_config_val.txt', 'w')\n",
    "                filewrite.write('')\n",
    "                filewrite.close()\n",
    "                \n",
    "                filewrite = open(file_root_save + '\\\\ANN\\\\log_val.txt', 'w')\n",
    "                filewrite.write('')\n",
    "                filewrite.close()\n",
    "                \n",
    "           ################################################################################################\n",
    "            #initialize config orddictionary\n",
    "            config = OrderedDict() #current config: hyper-parameter name, hyperparametre value\n",
    "            config_result = OrderedDict() # unique config as strings and its ANN results\n",
    "            virgin = 1\n",
    "\n",
    "            for hp_name in hp_names:\n",
    "                config[hp_name] = init_hp_val (hp_name, hp_names, cv_config)\n",
    "            \n",
    "            config_result[make_config_str(config)] = []  \n",
    "\n",
    "            best_config = make_config_str(config)\n",
    "            best_config_acc = -1\n",
    "            best_config_acc_all_inits_folds = []\n",
    "            \n",
    "            for i in range (0, k_fold * num_inits):\n",
    "                best_config_acc_all_inits_folds.append(-1)\n",
    "            ################################################################################################ \n",
    "            \n",
    "            for round in range (0, 5):\n",
    "                #loop through and generate new challenger config\n",
    "                for hp_defender in hp_names:\n",
    "                    #print (hp_defender)\n",
    "                    hp_ind = hp_names.index(hp_defender)\n",
    "\n",
    "                    best_val = config[hp_defender]\n",
    "                    #make challenger config\n",
    "                    for val in cv_config[hp_ind][1:]:\n",
    "                        config[hp_defender] = val\n",
    "                        \n",
    "                        #proceeed only if non-repeating config\n",
    "                        if virgin == 1 or (make_config_str(config) not in config_result.keys()):\n",
    "                   ################################################################################################\n",
    "                            #print (make_config_str(config))\n",
    "                            #print (config_result.keys())\n",
    "                            virgin = 0\n",
    "\n",
    "                            ACC = []\n",
    "                            for n_inits in range (0, num_inits):\n",
    "                                #print (val, n_inits)\n",
    "                                ###############################################################################################################################\n",
    "                                for fold in range (0, k_fold):\n",
    "                                    #print (fold)\n",
    "\n",
    "\n",
    "                                    train_idx0 = TRAIN_IDX[fold]\n",
    "                                    test_idx0 = TEST_IDX[fold]\n",
    "\n",
    "                                    trn_ind_map = np.arange(0,len(train_idx0))\n",
    "                                    tst_ind_map = np.arange(0,len(test_idx0))\n",
    "\n",
    "                                    random.shuffle(trn_ind_map)\n",
    "                                    random.shuffle(tst_ind_map)\n",
    "\n",
    "                                    y_train = LABELS0_go[train_idx0[trn_ind_map]]\n",
    "                                    y_test = LABELS0_go[test_idx0[tst_ind_map]]\n",
    "                                \n",
    "\n",
    "                                    X_train0 = pickle.load(open(file_root_feature + '\\\\Z_all_classes_train_fold_' + str(fold) + \n",
    "                                                                '_lambda_' + str(float(config['_lambda'].strip())) + \".pickle\", 'rb'))\n",
    "\n",
    "                                    X_test0 = pickle.load(open( file_root_feature + '\\\\Z_all_classes_test_fold_' + str(fold) + \n",
    "                                                               '_lambda_' + str(float(config['_lambda'].strip())) + \".pickle\", 'rb'))\n",
    "\n",
    "\n",
    "                                    X_train0 = X_train0[trn_ind_map]\n",
    "                                    X_test0 = X_test0[tst_ind_map]\n",
    "\n",
    "                                    #reshape to fit 2d covolution ( 1d doesnt work)\n",
    "                                    X_train = np.reshape(X_train0, [np.shape(X_train0)[0], 1, np.shape(X_train0)[1], np.shape(X_train0)[2]]).astype('float64')\n",
    "                                    X_test = np.reshape(X_test0, [np.shape(X_test0)[0], 1, np.shape(X_test0)[1], np.shape(X_test0)[2]]).astype('float64')\n",
    "\n",
    "                                    #convert to torch tensors for NN training\n",
    "                                    X_train = torch.from_numpy(X_train).float()\n",
    "                                    X_test = torch.from_numpy(X_test).float()\n",
    "                                    y_train = torch.from_numpy(y_train).long()\n",
    "                                    y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "                                    classes_all = [0,1,2,3] \n",
    "\n",
    "\n",
    "                                    #initilize model\n",
    "                                    model = Model_current(chn_inp = X_train.size()[-2], len_inp = X_train.size()[-1], nf = int(config['nf']), ks = int(config['ks']) , \n",
    "                                                  stride = int(config['stride']), act_f = config['act_fun'], nfc = int(config['nfc']))\n",
    "\n",
    "                                    Loss = nn.CrossEntropyLoss()\n",
    "\n",
    "                                    if config['optim'] == 'SGD':\n",
    "                                        lr = 0.2\n",
    "                                        optimizer = optim.SGD(model.parameters(), lr = lr)\n",
    "                                        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor= 0.5, min_lr=0.001, cooldown = 5)\n",
    "\n",
    "                                    elif 'ADAM_' in config['optim']:\n",
    "                                        lr = float(config['optim'].split('_')[1])\n",
    "                                        optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "                                        scheduler = None\n",
    "\n",
    "\n",
    "                                    ###############################################################################################################################         \n",
    "                                    #set save_path to None if we dont want to save the nn weights\n",
    "                                    save_path = None\n",
    "                                    if to_save == 1:\n",
    "                                        save_path = file_root_save + '\\\\ANN\\\\model_config_'+ str(make_config_str(config)) + '_' + 'n_inits_' + str(n_inits)+ '_fold_' + str(fold) + '.pt'\n",
    "\n",
    "                                    #Train and test NN and save the best weights\n",
    "                                    Train_acc_c, Test_acc_c, Train_loss, Test_loss, best_epoch, best_eval_acc, best_eval_acc_c = train_test_NN(\n",
    "                                        save_path, X_train, y_train.long(), X_test, y_test.long(), \n",
    "                                                      model, Loss, optimizer, scheduler, num_epoch, batch_size, classes_all)\n",
    "\n",
    "                                    if to_save == 1:\n",
    "                                        pickle.dump( Train_acc_c, open(file_root_save + '\\\\ANN\\\\Train_acc_c_config_'+ make_config_str(config) + '_' + str(n_inits)+ '_fold_' + str(fold) + \".pickle\", \"wb\" ) )\n",
    "                                        pickle.dump( Test_acc_c, open(file_root_save +  '\\\\ANN\\\\Test_acc_c_config_'+ make_config_str(config) + '_' + str(n_inits)+  '_fold_' + str(fold) + \".pickle\", \"wb\" ) )\n",
    "                                    \n",
    "                                    plot= 0\n",
    "                                    if n_inits == 0 and plot == 1:\n",
    "                                        plt.plot(np.average(Train_acc_c, axis = 1), 'b')\n",
    "                                        plt.plot(np.average(Test_acc_c, axis = 1), 'r')\n",
    "                                        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "                                    #calc accuracy\n",
    "                                    fold_ave = np.average(best_eval_acc_c)\n",
    "                                    #print ('fold', fold, ' fold acc ', fold_ave)\n",
    "                                    ACC.append(fold_ave)\n",
    "                                ###############################################################################################################################\n",
    "                            config_result[make_config_str(config)] = [np.average(ACC)]\n",
    "\n",
    "                            if to_save == 1:\n",
    "                                pickle.dump(ACC, open(file_root_save + '\\\\ANN\\\\ACC_' + make_config_str(config) + '.pickle', 'wb'))\n",
    "                                \n",
    "                            if np.average(ACC) > best_config_acc:\n",
    "                                w,p = stats.wilcoxon(ACC, best_config_acc_all_inits_folds)\n",
    "\n",
    "                                if to_save == 1:\n",
    "                                    filewrite = open(file_root_save + '\\\\ANN\\\\log_val.txt', 'a')\n",
    "                                    filewrite.write(make_config_str(config) + ' ' + str(np.average(ACC)) + \n",
    "                                                        ' wil_'+ str(w) + '_' + str(p/2.0))\n",
    "                                    if p/2.0 < 0.05:\n",
    "                                        filewrite.write(' ACCEPTED' + '\\n')\n",
    "                                    else:\n",
    "                                        filewrite.write(' REJECTED' + '\\n')\n",
    "\n",
    "                                    filewrite.close()\n",
    "\n",
    "\n",
    "                                if p/2.0 < 0.05:\n",
    "                                    best_val = val\n",
    "                                    best_config = make_config_str(config)\n",
    "                                    best_config_acc  = np.average(ACC)\n",
    "                                    best_config_acc_all_inits_folds = ACC\n",
    "\n",
    "                                    #save w, p, current, previous config name\n",
    "                                    if to_save == 1:\n",
    "                                        filewrite = open(file_root_save + '\\\\ANN\\\\best_config_val.txt', 'a')\n",
    "\n",
    "                                        filewrite.write(best_config + ' ' + str(best_config_acc) + \n",
    "                                                        ' wil_'+ str(w) + '_' + str(p/2.0) +  '\\n')\n",
    "                                        filewrite.close()\n",
    "\n",
    "                    ################################################################################################            \n",
    "                    config[hp_defender] = best_val                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f2dc75eed2f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'hp' is not defined"
     ]
    }
   ],
   "source": [
    "config[hp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portion_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\trans_learn_cv_30_covs_class_correction_not_centered\\\\A04\\\\4s\\\\cv_100'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_root_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['act_fun', 'leaky_relu'],\n",
       " ['nf', '8', '16', '32'],\n",
       " ['ks', '4', '8', '16'],\n",
       " ['stride', '2'],\n",
       " ['nfc', '20', '60', '180'],\n",
       " ['optim', 'ADAM_0.001'],\n",
       " ['_lambda', ' 0']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
