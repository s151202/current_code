{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('D:\\Diamond\\code')\n",
    "from csp_james_2 import *\n",
    "\n",
    "sys.path.append('D:\\Diamond\\code')\n",
    "from thesis_funcs_19_03 import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import csv\n",
    "from random import randint\n",
    "import random\n",
    "import datetime\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_root  = 'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\gold_stand\\\\'\n",
    "config_root= 'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\configs\\\\'\n",
    "raw_data_root = 'E:\\\\Diamond\\\\bci_iv\\\\DATA\\\\2a\\\\extract_raw\\\\'\n",
    "\n",
    "\n",
    "k_fold = 10\n",
    "\n",
    "\n",
    "# initialize csp\n",
    "m = 2# m is Nw in the paper \"learning temporal information for brain-copmuter interface, Sakhavi et.al\"\n",
    "n_components = 2 * m  # pick some components\n",
    "down_sample_step = 20 #Hilbert evelope\n",
    "# select Ns pairs of csp filters\n",
    "Ns = 4\n",
    "\n",
    "CLASSES =[0,1]\n",
    "\n",
    "C_OVR = [0,1,2,3]\n",
    "\n",
    "balance_classes = 1\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "                                            # DEFINE FILTER BANK\n",
    "########################################################################################################################\n",
    "#Filter Bank\n",
    "FB = [[4., 8.], [8., 12.], [12., 16.], [16., 20.], [20., 24.], [24., 28.], [28., 32.], [32., 36.], [36., 40.]]\n",
    "FB = np.array(FB)\n",
    "\n",
    "#argumaents for Chebyl II filtering\n",
    "# Nyquist frequency\n",
    "\n",
    "# min. attenuation in stop band\n",
    "gstop = 50\n",
    "# max. attenuation in passband\n",
    "gpass= 3 \n",
    "\n",
    "\n",
    "EEG_PERIOD = [[2.5,6]]\n",
    "FS = [250]\n",
    "\n",
    "\n",
    "to_center_matrix = 0\n",
    "calc_kl_d = 0\n",
    "calc_mi_discrim  =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read _lambda values\n",
    "with open(config_root +'_lambda_config.csv', mode = 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    for row in csv_reader:\n",
    "        _lambda_list_str = row[1:]\n",
    "csv_file.close()        \n",
    "\n",
    "#create _lambda value in list\n",
    "_lambda_list = []\n",
    "for i in _lambda_list_str:\n",
    "    _lambda_list.append(float(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\THINKPAD\\Anaconda3\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "D:\\THINKPAD\\Anaconda3\\lib\\site-packages\\scipy\\signal\\signaltools.py:1593: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  h = h[ind]\n"
     ]
    }
   ],
   "source": [
    "to_save = 1\n",
    "\n",
    "portion = 0.1\n",
    "portion_train = str(int(portion*100)) #mistake carried over - cv_train is actually the portion of training data used, and the directory name\n",
    "cv_train_size = 0.5 #cv_train_size if the actually cv split\n",
    "\n",
    "for subject in range(6, 7):\n",
    "    print (subject)\n",
    "    filename_T = 'A0'+str(subject)+'T'\n",
    "    filename_E = 'A0'+str(subject)+'E'\n",
    "    #ilename_save = filename\n",
    "    #rint (filename_save)\n",
    "    \n",
    "    file_root  = save_root + 'A0'+str(subject) + '\\\\4s\\\\'\n",
    "    k_file_root = file_root + 'pt_'+ portion_train + '\\\\'\n",
    "    \n",
    "    eeg_period = EEG_PERIOD[0]\n",
    "    fs = FS[0]\n",
    "    \n",
    "    #set load_idx to 0 if we want to create new and overwirite old T_IND files\n",
    "    COVS_AL_FD,  EEG_filt_FB_go, LABELS0_go, TRAIN_IDX, TEST_IDX, Train_idx = calc_k_covs_all_fold_current(filename_T, raw_data_root, \n",
    "                                                                                                            portion, k_file_root, \n",
    "                                                                                                            balance_classes, \n",
    "                                                                                                   FB,  gpass, gstop, fs, eeg_period, \n",
    "                                                                                                   k_fold, C_OVR, load_idx = 0, \n",
    "                                                                                                   cv_train_size = cv_train_size, \n",
    "                                                                                                 to_center_matrix = to_center_matrix)\n",
    "    \n",
    "    if to_save == 1:\n",
    "        pickle.dump(TRAIN_IDX , open(file_root +'pt_'+ portion_train + '\\\\TRAIN_IDX' + \".pickle\", \"wb\" ) )\n",
    "\n",
    "        pickle.dump(TEST_IDX , open(file_root +'pt_'+ portion_train + '\\\\TEST_IDX' + \".pickle\", \"wb\" ) )\n",
    "\n",
    "        pickle.dump(LABELS0_go , open(file_root +'pt_'+ portion_train + '\\\\LABELS0_go' + \".pickle\", \"wb\" ) )\n",
    "        \n",
    "    for fold in range (0, k_fold):\n",
    "        Covs_k = COVS_AL_FD[fold] #9 4 2 22 22 \n",
    "        for _lambda in _lambda_list[0:1]:\n",
    "            for c_ovr in C_OVR:\n",
    "                       \n",
    "                W_B = []\n",
    "                for i in range (0, len(FB)):\n",
    "                    W_B.append([])\n",
    "                    \n",
    "                \n",
    "                train_idx = Train_idx[fold][c_ovr]\n",
    "                EEG_train = EEG_filt_FB_go[:, train_idx, :]    \n",
    "                LABELS_train = LABELS0_go[train_idx]\n",
    "                LABELS_train = make_ovr_01_labels(LABELS_train, c_ovr)\n",
    "                \n",
    "                V= [] \n",
    "                for tr in range (0, len(train_idx)):\n",
    "                    V.append([])\n",
    "                \n",
    "                \n",
    "                for fb in range (0, len(FB)):\n",
    "                    \n",
    "                    \n",
    "                    C_ck = (1-_lambda)*Covs_k[fb, c_ovr] #+ _lambda*sec_term \n",
    "                    \n",
    "                    eigen_vectors_sorted, eigen_values = calc_sort_eigenvectors(C_ck)\n",
    "                    W_b_ = np.concatenate ( [eigen_vectors_sorted[:, 0:int(m)],  eigen_vectors_sorted[:, -int(m):]], axis = 1)\n",
    "                    W_B[fb].append(W_b_)\n",
    "\n",
    "\n",
    "\n",
    "                    for tr in range (0, len(train_idx)):\n",
    "                        eeg = EEG_train[fb, tr, :]\n",
    "\n",
    "                        #calculate features\n",
    "                        v_bi = csp_features(W_b_, m, eeg)\n",
    "\n",
    "                        #contruct feature matrix\n",
    "                        V[tr].append(v_bi)\n",
    "                        \n",
    "                V = np.array(V)\n",
    "                V = V.reshape([np.shape(V)[0], np.shape(V)[1]*np.shape(V)[2]]) \n",
    "                W_B = np.array(W_B).squeeze()\n",
    "\n",
    "                #follow MIBIF Algorithm in bci_iv_fbcsp paper\n",
    "                F = np.transpose(V)  \n",
    "\n",
    "                ####CALCULATE MUTUAL INFORMATION FOR THE FEATURES\n",
    "                I_fj = calc_MI(FB, m, CLASSES, LABELS_train, F)\n",
    "\n",
    "                ####SORT FEATURES ACCORDING TO MUTAUL INFORMATION\n",
    "                # I_fj_sorted is the indices of features ranked by decending mutal information, in shape (num_features, );\n",
    "                #where num_features = 2* m * num_FB\n",
    "                I_fj_sorted = np.argsort(I_fj)[::-1]\n",
    "\n",
    "\n",
    "                #the filter bank indices from which the features come from, in shape (num_features, )\n",
    "                FB_IND = np.floor(I_fj_sorted/(2*m)).astype(int)\n",
    "                #the filter channel (csp.eigen_vectors_sorted column) indiceis from which the features come from, in shape (num_features, )\n",
    "                FILTER_IND = (I_fj_sorted) - FB_IND * (2*m)\n",
    "\n",
    "                #combine the filterbank indicies and the CSP filter indicies, \n",
    "                #first column tells which filter bank the feature came from, \n",
    "                #second column tells which csp filter channel the feature came from\n",
    "                FB_FILTER_IND = np.array(list(zip(FB_IND, FILTER_IND)))\n",
    "                \n",
    "                if to_save == 1:\n",
    "                    pickle.dump( W_B, open(file_root + 'pt_' + portion_train\n",
    "                                                    + '\\\\W_B_fold_' + str(fold) + \n",
    "                                           '_c_ovr_' + str(c_ovr) + '_lambda_' + str(_lambda) +\n",
    "                                           \".pickle\", \"wb\" ) )\n",
    "\n",
    "                    pickle.dump( FB_FILTER_IND, open(file_root + 'pt_' + portion_train + '\\\\FB_FILTER_IND_fold_' + str(fold) + \n",
    "                                           '_c_ovr_' + str(c_ovr) + '_lambda_' + str(_lambda) +\n",
    "                                           \".pickle\", \"wb\" ) )\n",
    "                    \n",
    "    \n",
    "     ########################################################################################################################\n",
    "\n",
    "    for fold in range (0, k_fold):\n",
    "        #print ('fold', fold)\n",
    "        for _lambda in _lambda_list[0:1]:\n",
    "            for c_ovr in C_OVR:\n",
    "                #print (c_ovr)\n",
    "\n",
    "\n",
    "                #load in csp filters and mutual informtaion ranked indicies\n",
    "                W_B = pickle.load(open( file_root + 'pt_' + portion_train\n",
    "                                                    + '\\\\W_B_fold_' + str(fold) + \n",
    "                                           '_c_ovr_' + str(c_ovr) + '_lambda_' + str(_lambda) + \n",
    "                                           \".pickle\", 'rb'))\n",
    "\n",
    "\n",
    "                FB_FILTER_IND = pickle.load(open( file_root + 'pt_' + portion_train\n",
    "                                                    + '\\\\FB_FILTER_IND_fold_' + str(fold) + \n",
    "                                           '_c_ovr_' + str(c_ovr) + '_lambda_' + str(_lambda) + \n",
    "                                           \".pickle\", 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #find the selected csp filters indicies\n",
    "                FB_FILTER_IND_slt = find_selected_csp_filters(Ns, m, FB_FILTER_IND)\n",
    "\n",
    "                #construct selected csp filters, W_B_slt has shape (2*Ns, num_chls), (8,22) for example\n",
    "                W_B_slt = W_B[FB_FILTER_IND_slt[:,0], :, FB_FILTER_IND_slt[:,1]]\n",
    "\n",
    "\n",
    "\n",
    "                #load in training eeg signals and testing EEG\n",
    "                train_idx = TRAIN_IDX[fold]\n",
    "                test_idx = TEST_IDX[fold]\n",
    "                EEG_train_FB = EEG_filt_FB_go[:,train_idx,:]\n",
    "                EEG_test_FB = EEG_filt_FB_go[:,test_idx,:]\n",
    "                #pick only the eeg signals filtered by selected filter banks\n",
    "                EEG_train_FB_slt = EEG_train_FB[FB_FILTER_IND_slt[:,0], :]\n",
    "                EEG_test_FB_slt = EEG_test_FB[FB_FILTER_IND_slt[:,0], :]\n",
    "\n",
    "                #transform into z space, then take the hilbert envelope of the transformed signal\n",
    "                Z_env_train = calc_z_features(W_B_slt, EEG_train_FB_slt, Ns, down_sample_step)\n",
    "                Z_env_test = calc_z_features(W_B_slt, EEG_test_FB_slt, Ns, down_sample_step)\n",
    "\n",
    "                #concatenate all classes\n",
    "                if c_ovr == C_OVR[0]:\n",
    "                    Z_all_classes_train = Z_env_train\n",
    "                    Z_all_classes_test = Z_env_test\n",
    "                else:\n",
    "                    Z_all_classes_train = np.concatenate((Z_all_classes_train, Z_env_train), axis = 0)\n",
    "                    Z_all_classes_test = np.concatenate((Z_all_classes_test, Z_env_test), axis = 0)\n",
    "\n",
    "\n",
    "            #trasnpose into shape (num_trials, num_features, sample points)\n",
    "            Z_all_classes_train = np.transpose(Z_all_classes_train, [1,0,2])\n",
    "            Z_all_classes_test = np.transpose(Z_all_classes_test, [1,0,2])\n",
    "\n",
    "            #save the Z space hilbert envelop signals\n",
    "            if to_save == 1:\n",
    "                pickle.dump( Z_all_classes_train, open(file_root +'pt_' + portion_train\n",
    "                                                    + '\\\\Z_all_classes_train_fold_' + str(fold) + '_lambda_' + str(_lambda) + \".pickle\", \"wb\" ) )\n",
    "\n",
    "                pickle.dump( Z_all_classes_test, open(file_root +'pt_' + portion_train\n",
    "                                                    + '\\\\Z_all_classes_test_fold_' + str(fold) + '_lambda_' + str(_lambda) + \".pickle\", \"wb\" ) )\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portion_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 2, 2, 3, 3], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
