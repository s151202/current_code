{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('D:\\Diamond\\code')\n",
    "from csp_james_2 import *\n",
    "\n",
    "sys.path.append('D:\\Diamond\\code')\n",
    "from thesis_funcs_19_03 import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import csv\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meth = 'gold_stand' #gold_standï¼Œtl_comp_csp_kld , tl_comp_csp_mi\n",
    "raw_data_root = 'E:\\\\Diamond\\\\bci_iv\\\\DATA\\\\2a\\\\extract_raw\\\\'\n",
    "config_root= 'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\configs\\\\'\n",
    "\n",
    "feature_root = 'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\' + meth + '\\\\'\n",
    "model_root = feature_root\n",
    "save_root = model_root + 'eval456\\\\'\n",
    "\n",
    "\n",
    "#load in cv config grid\n",
    "hp_names  =[] #all the hyper-parameter names to be validated\n",
    "with open(config_root +'cv_config.csv', mode = 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    for row in csv_reader:\n",
    "        hp_names.append((row[0]).strip())\n",
    "\n",
    "with open(config_root +'_lambda_config.csv', mode = 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    for row in csv_reader:\n",
    "        hp_names.append((row[0]).strip())\n",
    "csv_file.close()\n",
    "\n",
    "\n",
    "\n",
    "num_inits = 5\n",
    "k_fold = 10\n",
    "\n",
    "# initialize csp\n",
    "m = 2# m is Nw in the paper \"learning temporal information for brain-copmuter interface, Sakhavi et.al\"\n",
    "n_components = 2 * m  # pick some components\n",
    "down_sample_step = 20 #Hilbert evelope\n",
    "# select Ns pairs of csp filters\n",
    "Ns = 4\n",
    "\n",
    "CLASSES =[0,1]\n",
    "\n",
    "C_OVR = [0,1,2,3]\n",
    "\n",
    "balance_classes = 1\n",
    "\n",
    "########################################################################################################################\n",
    "                                            # DEFINE FILTER BANK\n",
    "########################################################################################################################\n",
    "#Filter Bank\n",
    "FB = [[4., 8.], [8., 12.], [12., 16.], [16., 20.], [20., 24.], [24., 28.], [28., 32.], [32., 36.], [36., 40.]]\n",
    "FB = np.array(FB)\n",
    "\n",
    "#argumaents for Chebyl II filtering\n",
    "# Nyquist frequency\n",
    "\n",
    "# min. attenuation in stop band\n",
    "gstop = 50\n",
    "# max. attenuation in passband\n",
    "gpass= 3 \n",
    "\n",
    "EEG_PERIOD = [[2.5,6]]\n",
    "FS = [250]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\gold_stand\\\\eval456\\\\'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_root  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt_train 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\THINKPAD\\Anaconda3\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "D:\\THINKPAD\\Anaconda3\\lib\\site-packages\\scipy\\signal\\signaltools.py:1593: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  h = h[ind]\n",
      "D:\\Diamond\\code\\thesis_funcs_19_03.py:1334: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = nnF.softmax(self.fc3(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A01E [0. 0. 1. 0.] 0.25 0.0\n",
      "A02E [0. 0. 1. 0.] 0.25 0.0\n",
      "A03E [0.01492537 0.         0.         1.        ] 0.2537313432835821 0.004895829610835123\n",
      "A04E [0. 0. 1. 0.] 0.25 0.0\n",
      "A05E [0. 0. 1. 0.] 0.25 0.0\n",
      "A06E [0.        0.        0.7962963 0.1509434] 0.23680992313067784 -0.017839616650308976\n",
      "A07E [0. 0. 0. 1.] 0.25 0.0\n",
      "A08E [0. 0. 1. 0.] 0.25 0.0\n",
      "A09E [0. 0. 0. 1.] 0.25 0.0\n"
     ]
    }
   ],
   "source": [
    "for portion_train in [1]:\n",
    "    print ('pt_train', portion_train)\n",
    "\n",
    "    if to_save == 1:\n",
    "        filewrite = open(save_root + '4s_' + str(int(portion_train*100))+'_best_config_eval_acc_all_subjects.txt', 'w')\n",
    "        filewrite.write('')\n",
    "        filewrite.close()\n",
    "\n",
    "        filewrite = open(save_root + '4s_' + str(int(portion_train*100))+'_best_config_eval_acc_all_subjects.txt', 'a')\n",
    "        filewrite.write('subject, ')\n",
    "        for f in range (0, len(C_OVR)-1):\n",
    "            filewrite.write('class '+ str(C_OVR[f]+1) + ', ')\n",
    "        filewrite.write('class ' + str(C_OVR[-1]+1) + ', average'+ ', best_model_init_fold\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for subject in range (1,10):\n",
    "\n",
    "        filename = 'A0'+str(subject)+'E'\n",
    "        filename_save = filename\n",
    "        #print (filename_save)\n",
    "\n",
    "        eeg_period = EEG_PERIOD[0]\n",
    "        fs = FS[0]\n",
    "   \n",
    "        \n",
    "        for run_win in range (0,1):\n",
    "            if run_win == 0:\n",
    "                file_root_feature =  feature_root + filename_save[:-1] + '\\\\4s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                file_root_model = model_root + filename_save[:-1] + '\\\\4s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                #file_root_save = save_root + filename_save[:-1] + '\\\\4s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                #len_inp = 44\n",
    "            elif run_win == 1:\n",
    "                file_root_feature = feature_root + filename_save[:-1] + '\\\\2s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                file_root_model = model_root + filename_save[:-1] + '\\\\2s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                #file_root_save = save_root + filename_save[:-1] + '\\\\2s\\\\' + 'pt_' + str(int(portion_train*100))\n",
    "                #len_inp = 25\n",
    "                \n",
    "            ###################################################################################################################\n",
    "                            #load best config\n",
    "            ###################################################################################################################\n",
    "            #load in best config line\n",
    "            config_file = open(file_root_model + '\\\\ANN\\\\best_config_val.txt', 'r')\n",
    "            config_log= config_file.readlines()\n",
    "            config_file.close()\n",
    "            for i in range (0,len(config_log)):\n",
    "                line  = config_log[(i + 1) * -1]\n",
    "                if '_act_fun_' in line: #and  line.split(' ')[0].split('_lambda_')[1] == '0':\n",
    "                    break\n",
    "\n",
    "            #extract best config values and make into dictionary\n",
    "            config = OrderedDict()\n",
    "            for hp_ind in range(0, len(hp_names)-1):\n",
    "                config[hp_names[hp_ind]] =  (line.split(hp_names[hp_ind] + '_')[1].split('_'+hp_names[hp_ind+1]+'_')[0])\n",
    "            config[hp_names[-1]] = line.split(hp_names[-1]+'_')[1].split(' ')[0]\n",
    "            \n",
    "            \n",
    "            ###################################################################################################################\n",
    "                    #load raw data\n",
    "            ###################################################################################################################\n",
    "            #load raw eeg and labels\n",
    "            EEG_extract_raw = pickle.load(open(raw_data_root\n",
    "                                                                    + filename_save + '.pickle', 'rb'),encoding='iso-8859-1')\n",
    "            #Class labels\n",
    "            LABELS_raw = pickle.load(open(raw_data_root\n",
    "                                                                + filename_save + \"_LABELS.pickle\", 'rb'), encoding='iso-8859-1')\n",
    "\n",
    "\n",
    "            LABELS = LABELS_raw - 1 #already in 1,2,3,4, the labels are. but we nned them to be likw 0,1,2,3\n",
    "       \n",
    "            #RUN THIS CODE ONLY ONCE, LABELS0 is the original labels, and LABELS will be changed in one-versus-rest strategy, later\n",
    "            LABELS0 = LABELS.copy()\n",
    "            \n",
    "            \n",
    "            ########################################################################################################################\n",
    "                                        #APPLY FILTER BANK\n",
    "            ########################################################################################################################\n",
    "            #Store Filter bank filtered raw EEG data, in the shape of num_filter_bank X num_trials X num_chanl X num_samples\n",
    "            #initiate empty matrix\n",
    "            EEG_filt_FB_L = np.empty( [len(FB), \n",
    "                                     np.shape(EEG_extract_raw)[0], np.shape(EEG_extract_raw)[1],np.shape(EEG_extract_raw)[2]] )\n",
    "\n",
    "            Nf = fs / 2.\n",
    "            for fb in range (0, len(FB)):\n",
    "                passband = FB[fb]\n",
    "                stopband = FB[fb] + np.array([-2., +2.])\n",
    "\n",
    "                EEG_filt_FB_L[fb] = filter_signal(EEG_extract_raw, passband, stopband, Nf, gpass, gstop)\n",
    "\n",
    "\n",
    "            EEG_filt_FB = EEG_filt_FB_L\n",
    "            \n",
    "            #trake only the MI 3.5 seconds\n",
    "            EEG_filt_FB_go = EEG_filt_FB[:,:,:,int(eeg_period[0]*fs):int(eeg_period[1]*fs)]\n",
    "            LABELS0_go = LABELS0.copy()\n",
    "            \n",
    "            \n",
    "            \n",
    "            ###########################################################################################################################\n",
    "    \n",
    "            pred_indi = []\n",
    "            ############################################################################################################################\n",
    "            OUT = 0\n",
    "            \n",
    "            best_mod_acc_prod = 0 #initialise best model average class acc\n",
    "            best_mod_kappa = -2\n",
    "            best_model = [0,0] #which model performs the best? model id, init = best_model[0], fold = best_model[1]\n",
    "    \n",
    "            for fold in range (0, k_fold):\n",
    "                #print ('fold', fold)\n",
    "\n",
    "                pred_indi.append([])\n",
    "                \n",
    "                for c_ovr in C_OVR:\n",
    "                    #print (c_ovr)\n",
    "                    #load in csp filters and mutual informtaion ranked indicies\n",
    "                    W_B = pickle.load(open( file_root_feature +'\\\\W_B_fold_' + str(fold) + \n",
    "                                               '_c_ovr_' + str(c_ovr) + '_lambda_' + str(float(config['_lambda'])) + \n",
    "                                               \".pickle\", 'rb'))\n",
    "\n",
    "\n",
    "                    FB_FILTER_IND = pickle.load(open( file_root_feature +  '\\\\FB_FILTER_IND_fold_' + str(fold) + \n",
    "                                               '_c_ovr_' + str(c_ovr) + '_lambda_' + str(float(config['_lambda'])) + \n",
    "                                               \".pickle\", 'rb'))\n",
    "\n",
    "                    #find the selected csp filters indicies\n",
    "                    FB_FILTER_IND_slt = find_selected_csp_filters(Ns, m, FB_FILTER_IND)\n",
    "\n",
    "                    #construct selected csp filters, W_B_slt has shape (2*Ns, num_chls), (8,22) for example\n",
    "                    W_B_slt = W_B[FB_FILTER_IND_slt[:,0], :, FB_FILTER_IND_slt[:,1]]\n",
    "\n",
    "                    EEG_FB_slt = EEG_filt_FB_go[FB_FILTER_IND_slt[:,0],:]\n",
    "\n",
    "                    #transform into z space, then take the hilbert envelope of the transformed signal\n",
    "                    Z_env = calc_z_features(W_B_slt, EEG_FB_slt, Ns, down_sample_step)\n",
    "\n",
    "                    #concatenate all classes\n",
    "                    if c_ovr == C_OVR[0]:\n",
    "                        Z_all_eval = Z_env\n",
    "                    else:\n",
    "                        Z_all_eval = np.concatenate((Z_all_eval, Z_env), axis = 0)\n",
    "\n",
    "                #reshape into ANN input size        \n",
    "                Z_all_eval = np.transpose(Z_all_eval, [1,0,2])\n",
    "                X_eval = np.reshape(Z_all_eval, [np.shape(Z_all_eval)[0], 1, np.shape(Z_all_eval)[1], np.shape(Z_all_eval)[2]])\n",
    "                X_eval = torch.from_numpy(X_eval).float()\n",
    "                \n",
    "                #initilize ANN model\n",
    "                model = Model_current(chn_inp = X_eval.size()[-2], len_inp = X_eval.size()[-1], nf = int(config['nf']), ks = int(config['ks']) , \n",
    "                                  stride = int(config['stride']), act_f = config['act_fun'], nfc = int(config['nfc']))\n",
    "                \n",
    "                for n_inits in range (0, num_inits):\n",
    "                    save_path = file_root_model + '\\\\ANN\\\\model_config_'+ line.split(' ')[0] + '_n_inits_'+ str(n_inits) +'_fold_' + str(fold) + '.pt'\n",
    "                    \n",
    "                    #modify th econv1 weights to each trained kernel's mean\n",
    "                    params = torch.load(save_path)\n",
    "                    for n_f in range (0, params['conv1.weight'].size()[0]):\n",
    "\n",
    "                        modified_conv_w = torch.ones(params['conv1.weight'].size()[-3:]) * torch.mean(params['conv1.weight'][n_f])\n",
    "                        params['conv1.weight'][n_f] = modified_conv_w\n",
    "\n",
    "                    model.load_state_dict(params)\n",
    "                    model.eval()\n",
    "\n",
    "                    #predictoin, sum up the output (probability of being class) predicted at each fold, tehn the class with the max probability if the class prediction\n",
    "                    out = model(X_eval)\n",
    "                    OUT = OUT + out\n",
    "\n",
    "                    #print out class precition at each fold\n",
    "                    pred = torch.argmax(out, dim = 1).numpy()\n",
    "                    #print (str(n_inits), np.average(calc_class_acc(pred, LABELS0, C_OVR)))\n",
    "                    if cohen_kappa_score(LABELS0, pred) > best_mod_kappa:\n",
    "                        best_model = [n_inits, fold]\n",
    "                        best_mod_acc_prod = np.average(calc_class_acc(pred, LABELS0, C_OVR))\n",
    "                        best_mod_kappa = cohen_kappa_score(LABELS0, pred)\n",
    "\n",
    "                    #pred_indi[fold].append(cohen_kappa_score(LABELS0, pred))\n",
    "                    \n",
    "                    \n",
    "            #final prediciotn using all trained ANNs   \n",
    "            PRED = torch.argmax(OUT, dim = 1).numpy()\n",
    "            acc_c = calc_class_acc(PRED, LABELS0, C_OVR)\n",
    "            kappa = cohen_kappa_score(LABELS0, PRED)\n",
    "            print(filename, acc_c, np.average(acc_c), kappa)\n",
    "            \n",
    "            \n",
    "            if to_save == 1:\n",
    "                filewrite.write(str(subject) + ', ')\n",
    "\n",
    "                for a in acc_c:\n",
    "                    filewrite.write(str(round(a*100,2)) + ', ')\n",
    "                filewrite.write(str(round(np.average(acc_c)*100, 2)) +' '+'('+str(round(kappa, 3))+')' +', ' + str(best_model[0])+'_'+str(best_model[1]) + '_'+ str(best_mod_acc_prod) + '(' + str(best_mod_kappa) + ')'  +'\\n')\n",
    "                \n",
    "                \n",
    "    if to_save == 1:\n",
    "        filewrite.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'83.33 (0.777), 3_1_0.543014730897462(-2)'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mod_kappa = -2\n",
    "str(round(np.average(acc_c)*100, 2)) +' '+'('+str(round(kappa, 3))+')' +', ' + str(best_model[0])+'_'+str(best_model[1]) + '_'+ str(best_mod_acc_prod) + '(' + str(best_mod_kappa) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'88.24 (0.843), 0_0'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mod_acc_prod = 0\n",
    "best_model = [0,0]\n",
    "str(round(np.average(acc_c)*100, 2)) +' '+'('+str(round(kappa, 3))+')' +', ' + str(best_model[0])+'_'+str(best_model[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-2defb46115bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cl' is not defined"
     ]
    }
   ],
   "source": [
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27137472723665934, 0.7477779721809116)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(calc_class_acc(pred, LABELS0, C_OVR)), np.average(calc_class_acc(pred, LABELS0, C_OVR))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97183099, 0.54285714, 0.91304348, 0.56338028])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_class_acc(pred, LABELS0, C_OVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['_lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\gold_stand\\\\A01\\\\4s\\\\pt_100'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_root_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 281, 22, 875), (281,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(EEG_filt_FB_go), np.shape(LABELS0_go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\gold_stand\\\\A01\\\\4s\\\\pt_100'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_root_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
