{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('D:\\Diamond\\code')\n",
    "from csp_james_2 import *\n",
    "\n",
    "sys.path.append('D:\\Diamond\\code')\n",
    "from thesis_funcs_19_03 import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import csv\n",
    "from random import randint\n",
    "import random\n",
    "import datetime\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_root  = 'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\NBPW\\\\'\n",
    "config_root= 'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\configs\\\\'\n",
    "raw_data_root = 'E:\\\\Diamond\\\\bci_iv\\\\DATA\\\\2a\\\\extract_raw\\\\'\n",
    "feature_root = 'E:\\\\Diamond\\\\bci_iv\\\\MODELS\\\\fbcsp_mibif_cnn\\\\2a\\\\CURRENT\\\\gold_stand\\\\'\n",
    "\n",
    "\n",
    "k_fold = 10\n",
    "\n",
    "\n",
    "# initialize csp\n",
    "m = 2# m is Nw in the paper \"learning temporal information for brain-copmuter interface, Sakhavi et.al\"\n",
    "n_components = 2 * m  # pick some components\n",
    "down_sample_step = 20 #Hilbert evelope\n",
    "# select Ns pairs of csp filters\n",
    "Ns = 4\n",
    "\n",
    "CLASSES =[0,1]\n",
    "\n",
    "C_OVR = [0,1,2,3]\n",
    "\n",
    "balance_classes = 1\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "                                            # DEFINE FILTER BANK\n",
    "########################################################################################################################\n",
    "#Filter Bank\n",
    "FB = [[4., 8.], [8., 12.], [12., 16.], [16., 20.], [20., 24.], [24., 28.], [28., 32.], [32., 36.], [36., 40.]]\n",
    "FB = np.array(FB)\n",
    "\n",
    "#argumaents for Chebyl II filtering\n",
    "# Nyquist frequency\n",
    "\n",
    "# min. attenuation in stop band\n",
    "gstop = 50\n",
    "# max. attenuation in passband\n",
    "gpass= 3 \n",
    "\n",
    "\n",
    "EEG_PERIOD = [[2.5,6]]\n",
    "FS = [250]\n",
    "\n",
    "\n",
    "to_center_matrix = 0\n",
    "calc_kl_d = 0\n",
    "calc_mi_discrim  =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read _lambda values\n",
    "with open(config_root +'_lambda_config.csv', mode = 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    for row in csv_reader:\n",
    "        _lambda_list_str = row[1:]\n",
    "csv_file.close()        \n",
    "\n",
    "#create _lambda value in list\n",
    "_lambda_list = []\n",
    "for i in _lambda_list_str:\n",
    "    _lambda_list.append(float(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_lambda_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\THINKPAD\\Anaconda3\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    }
   ],
   "source": [
    " #set load_idx to 0 if we want to create new and overwirite old T_IND files\n",
    "k_file_root = None\n",
    "fs = FS[0]\n",
    "eeg_period = EEG_PERIOD[0]\n",
    "COVS_AL_FD,  EEG_filt_FB_go, LABELS0_go, TRAIN_IDX, TEST_IDX, Train_idx = calc_k_covs_all_fold_current(filename_T, raw_data_root, \n",
    "                                                                                                            portion, k_file_root, \n",
    "                                                                                                            balance_classes, \n",
    "                                                                                                   FB,  gpass, gstop, fs, eeg_period, \n",
    "                                                                                                   k_fold, C_OVR, load_idx = 0, \n",
    "                                                                                                   cv_train_size = 0.7, \n",
    "                                                                                                 to_center_matrix = to_center_matrix, calc_covs_all_fd = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 189)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(TRAIN_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS0_go1 = pickle.load(open(file_root_feature + '\\\\LABELS0_go.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "portion = 1\n",
    "portion_train = str(int(portion*100)) #mistake carried over - cv_train is actually the portion of training data used, and the directory name\n",
    "cv_train_size = 0.5 #cv_train_size if the actually cv split\n",
    "\n",
    "\n",
    "for subject in range(1, 2):\n",
    "    filename_T = 'A0'+str(subject)+'T'\n",
    "    file_root_feature =  feature_root + filename_T[:-1] + '\\\\4s\\\\' + 'pt_' + portion_train\n",
    "    LABELS0_go = pickle.load(open(file_root_feature + '\\\\LABELS0_go.pickle', 'rb'))\n",
    "    TRAIN_IDX = pickle.load(open(file_root_feature  + '\\\\TRAIN_IDX.pickle', 'rb'))\n",
    "    TEST_IDX = pickle.load(open(file_root_feature + '\\\\TEST_IDX.pickle', 'rb'))  \n",
    "    \n",
    "    for fold in range (0, 1):\n",
    "        #print (fold)\n",
    "\n",
    "        #load in csp filters and mutual informtaion ranked indicies\n",
    "        W_B = pickle.load(open( file_root + 'pt_' + portion_train\n",
    "                                            + '\\\\W_B_fold_' + str(fold) + \n",
    "                                   '_c_ovr_' + str(c_ovr) + '_lambda_' + str(_lambda_list[0]) + \n",
    "                                   \".pickle\", 'rb'))\n",
    "\n",
    "\n",
    "        FB_FILTER_IND = pickle.load(open( file_root + 'pt_' + portion_train\n",
    "                                            + '\\\\FB_FILTER_IND_fold_' + str(fold) + \n",
    "                                   '_c_ovr_' + str(c_ovr) + '_lambda_' + str(_lambda_list[0]) + \n",
    "                                   \".pickle\", 'rb'))\n",
    "\n",
    "\n",
    "        #find the selected csp filters indicies\n",
    "        FB_FILTER_IND_slt = find_selected_csp_filters(Ns, m, FB_FILTER_IND)\n",
    "\n",
    "        #construct selected csp filters, W_B_slt has shape (2*Ns, num_chls), (8,22) for example\n",
    "        W_B_slt = W_B[FB_FILTER_IND_slt[:,0], :, FB_FILTER_IND_slt[:,1]]\n",
    "        \n",
    "\n",
    "        \n",
    "        train_idx0 = TRAIN_IDX[fold]\n",
    "        test_idx0 = TEST_IDX[fold]\n",
    "\n",
    "        trn_ind_map = np.arange(0,len(train_idx0))\n",
    "        tst_ind_map = np.arange(0,len(test_idx0))\n",
    "\n",
    "        random.shuffle(trn_ind_map)\n",
    "        random.shuffle(tst_ind_map)\n",
    "\n",
    "        y_train = LABELS0_go[train_idx0[trn_ind_map]]\n",
    "        y_test = LABELS0_go[test_idx0[tst_ind_map]]\n",
    "\n",
    "        EEG_\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        X_train0 = pickle.load(open(file_root_feature + '\\\\Z_all_classes_train_fold_' + str(fold) + \n",
    "                                    '_lambda_' + str(_lambda_list[0]) + \".pickle\", 'rb'))\n",
    "\n",
    "        X_test0 = pickle.load(open( file_root_feature + '\\\\Z_all_classes_test_fold_' + str(fold) + \n",
    "                                   '_lambda_' + str(_lambda_list[0]) + \".pickle\", 'rb'))\n",
    "\n",
    "\n",
    "        X_train0 = X_train0[trn_ind_map]\n",
    "        X_test0 = X_test0[tst_ind_map]\n",
    "        \n",
    "        X_train = np.reshape(X_train0, (len(X_train0), -1))\n",
    "        X_test = np.reshape(X_test0, (len(X_test0), -1))\n",
    "        X_train = np.transpose(X_train)\n",
    "        X_test = np.transpose(X_test)\n",
    "        \n",
    "        P_w = [0.25, 0.25, 0.25, 0.25]\n",
    "        CLASSES = [0,1,2,3]\n",
    "        \n",
    "        PRED = []\n",
    "        PPP = []\n",
    "\n",
    "        for tr in range (0, 1):\n",
    "            pred, P_w_x = pred_NBPW(X_test[:, tr:tr+1], X_train, CLASSES, y_train, P_w)\n",
    "            PRED.append(pred)\n",
    "            PPP.append(P_w_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.sum(X_train0 * X_train0, axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1. 1. 1. 1.]\n",
      "1 [0.00770057 0.14850726 0.06081744 0.11021252]\n",
      "2 [0.0006902  0.02475718 0.00645558 0.0131924 ]\n",
      "3 [0.00013152 0.00451105 0.0001445  0.00032084]\n",
      "4 [2.22707634e-05 1.03407684e-04 1.79539234e-05 3.88271955e-05]\n",
      "5 [3.14344387e-06 2.78135819e-05 1.76225032e-06 4.75693208e-06]\n",
      "6 [4.25302949e-07 3.08811597e-06 2.06301896e-07 5.41843957e-07]\n",
      "7 [5.34809877e-08 2.10022784e-07 1.08466846e-08 3.61413496e-08]\n",
      "8 [5.25515315e-09 3.54077705e-08 1.73216189e-09 2.94001958e-09]\n",
      "9 [8.45330862e-10 2.29424346e-09 1.04051659e-10 1.76702855e-10]\n",
      "10 [1.66854327e-10 7.67288897e-10 2.45683708e-11 3.37285548e-11]\n",
      "11 [5.74851869e-12 7.56509417e-82 3.11121841e-12 2.87905281e-12]\n",
      "12 [4.53515973e-13 1.20074666e-82 3.85541421e-13 2.78053498e-13]\n",
      "13 [5.12991491e-14 1.64537991e-83 3.79102261e-14 1.83338178e-14]\n",
      "14 [8.97897198e-15 3.84138287e-84 4.84417438e-15 2.27536234e-15]\n",
      "15 [1.90423489e-15 2.55578158e-85 4.26939297e-16 2.69016033e-17]\n",
      "16 [5.18300367e-17 1.07446290e-86 1.60164800e-17 3.35726148e-19]\n",
      "17 [1.09622652e-18 1.26514521e-87 7.34162573e-19 5.91842704e-20]\n",
      "18 [2.32564994e-19 2.41715461e-88 1.34358779e-19 6.11018953e-21]\n",
      "19 [3.26475975e-20 3.07835864e-89 3.96208362e-21 7.39310978e-22]\n",
      "20 [2.08211305e-21 4.64706225e-90 3.65126744e-22 9.33673035e-23]\n",
      "21 [2.95963024e-22 1.13467095e-90 4.68202100e-23 1.40318628e-23]\n",
      "22 [3.72332823e-23 7.78290471e-92 4.43597918e-24 2.05818783e-24]\n",
      "23 [2.97630332e-24 9.29612578e-93 5.88322541e-25 2.24702089e-25]\n",
      "24 [3.85466933e-25 1.61925060e-93 6.96834885e-26 3.26620192e-26]\n",
      "25 [4.58747490e-26 2.08537616e-94 9.55234852e-27 2.65030667e-27]\n",
      "26 [4.43598648e-27 7.89907902e-97 1.30997964e-27 1.29001807e-28]\n",
      "27 [4.97542529e-28 1.72572547e-97 1.00060127e-28 2.05320365e-30]\n",
      "28 [5.16652692e-29 1.98675676e-98 1.75744827e-29 2.17340516e-31]\n",
      "29 [9.68947815e-30 2.62131499e-99 1.42236670e-30 5.84940962e-34]\n",
      "30 [2.16565584e-030 3.83701011e-100 2.19254211e-031 7.02051523e-035]\n",
      "31 [3.72858240e-031 4.79028692e-101 3.83129255e-033 1.33601545e-036]\n"
     ]
    }
   ],
   "source": [
    "F_selected = np.sum(X_train0 * X_train0, axis = -1) / 44\n",
    "LABELS_train = y_train\n",
    "test_f = np.sum(X_test0 * X_test0, axis = -1) / 44 \n",
    "test_f = test_f[0:1]\n",
    "F_selected = np.transpose(F_selected)\n",
    "test_f = np.transpose(test_f)\n",
    "\n",
    "#P_x_w = np.array([1., 1. ])\n",
    "P_x_w = np.ones(np.shape(CLASSES))\n",
    "\n",
    "for j in range (0, int(np.shape(F_selected)[0])):\n",
    "    print (j, P_x_w)\n",
    "\n",
    "    OE = np.empty(len(CLASSES))\n",
    "    P_xj_w = np.empty(len(CLASSES))\n",
    "\n",
    "\n",
    "    for w in CLASSES:\n",
    "        CLASS_idx_train = np.array(np.where(LABELS_train.squeeze() == w)).squeeze()\n",
    "\n",
    "        #equa.19\n",
    "        OEw = pred_OE(test_f, F_selected, j, CLASS_idx_train)\n",
    "        OE[w] = OEw\n",
    "\n",
    "    P_xj_w=  1./len(CLASS_idx_train) * OE\n",
    "\n",
    "    #equa.18\n",
    "    P_x_w = P_x_w * P_xj_w\n",
    "\n",
    "#equa.17\n",
    "P_x = sum(P_x_w * P_w)\n",
    "\n",
    "P_w_x = P_x_w * P_w / P_x\n",
    "\n",
    "pred = np.argmax(P_w_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7., 7., 8., 9.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(len(CLASSES)) * np.array([7,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,   8,  21,  22,  25,  28,  32,  39,  43,  45,  49,  60,  61,\n",
       "        63,  67,  71,  73,  78,  80,  85,  91,  93,  95,  99, 100, 106,\n",
       "       109, 110, 112, 118, 119, 120, 122, 124, 128, 130, 132, 139, 143,\n",
       "       147, 157, 161, 164, 173, 176, 177, 185, 187], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_train == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-e9fa2bf4e947>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mP_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_w_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_NBPW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Diamond\\code\\thesis_funcs_19_03.py\u001b[0m in \u001b[0;36mpred_NBPW\u001b[1;34m(test_f, F_selected, CLASSES, LABELS_train, P_w)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[1;31m#equa.18\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 980\u001b[1;33m         \u001b[0mP_x_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mP_x_w\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mP_xj_w\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    981\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m     \u001b[1;31m#equa.17\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,) (4,) "
     ]
    }
   ],
   "source": [
    " P_w = [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "pred, P_w_x = pred_NBPW(np.transpose(X_test[0:1]), np.transpose(X_train), [0,1,2,3], y_train, P_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1408, 84)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.transpose(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1408, 189)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape( np.transpose(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  8,   9,  11,  13,  18,  19,  25,  34,  37,  41,  43,  51,  53,\n",
       "         57,  60,  62,  68,  75,  76,  77,  85,  88,  89,  92,  95,  96,\n",
       "         98, 102, 107, 111, 116, 120, 127, 129, 138, 144, 150, 151, 156,\n",
       "        157, 158, 162, 171, 178, 179, 184], dtype=int64),)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_train.squeeze() ==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(np.shape([0,1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portion = 0.1\n",
    "portion_train = str(int(portion*100)) #mistake carried over - cv_train is actually the portion of training data used, and the directory name\n",
    "cv_train_size = 0.5 #cv_train_size if the actually cv split\n",
    "\n",
    "for subject in range(6, 7):\n",
    "    print (subject)\n",
    "    filename_T = 'A0'+str(subject)+'T'\n",
    "    filename_E = 'A0'+str(subject)+'E'\n",
    "    #ilename_save = filename\n",
    "    #rint (filename_save)\n",
    "    \n",
    "    file_root  = save_root + 'A0'+str(subject) + '\\\\4s\\\\'\n",
    "    k_file_root = file_root + 'pt_'+ portion_train + '\\\\'\n",
    "    \n",
    "    eeg_period = EEG_PERIOD[0]\n",
    "    fs = FS[0]\n",
    "    \n",
    "    #set load_idx to 0 if we want to create new and overwirite old T_IND files\n",
    "    COVS_AL_FD,  EEG_filt_FB_go, LABELS0_go, TRAIN_IDX, TEST_IDX, Train_idx = calc_k_covs_all_fold_current(filename_T, raw_data_root, \n",
    "                                                                                                            portion, k_file_root, \n",
    "                                                                                                            balance_classes, \n",
    "                                                                                                   FB,  gpass, gstop, fs, eeg_period, \n",
    "                                                                                                   k_fold, C_OVR, load_idx = 0, \n",
    "                                                                                                   cv_train_size = cv_train_size, \n",
    "                                                                                                 to_center_matrix = to_center_matrix)\n",
    "    \n",
    "    if to_save == 1:\n",
    "        pickle.dump(TRAIN_IDX , open(file_root +'pt_'+ portion_train + '\\\\TRAIN_IDX' + \".pickle\", \"wb\" ) )\n",
    "\n",
    "        pickle.dump(TEST_IDX , open(file_root +'pt_'+ portion_train + '\\\\TEST_IDX' + \".pickle\", \"wb\" ) )\n",
    "\n",
    "        pickle.dump(LABELS0_go , open(file_root +'pt_'+ portion_train + '\\\\LABELS0_go' + \".pickle\", \"wb\" ) )\n",
    "        \n",
    "        \n",
    "        \n",
    "     ########################################################################################################################\n",
    "\n",
    "    for fold in range (0, k_fold):\n",
    "        #print ('fold', fold)\n",
    "        for _lambda in _lambda_list[0:1]:\n",
    "            for c_ovr in C_OVR:\n",
    "                #print (c_ovr)\n",
    "\n",
    "\n",
    "                #load in csp filters and mutual informtaion ranked indicies\n",
    "                W_B = pickle.load(open( file_root + 'pt_' + portion_train\n",
    "                                                    + '\\\\W_B_fold_' + str(fold) + \n",
    "                                           '_c_ovr_' + str(c_ovr) + '_lambda_' + str(_lambda) + \n",
    "                                           \".pickle\", 'rb'))\n",
    "\n",
    "\n",
    "                FB_FILTER_IND = pickle.load(open( file_root + 'pt_' + portion_train\n",
    "                                                    + '\\\\FB_FILTER_IND_fold_' + str(fold) + \n",
    "                                           '_c_ovr_' + str(c_ovr) + '_lambda_' + str(_lambda) + \n",
    "                                           \".pickle\", 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #find the selected csp filters indicies\n",
    "                FB_FILTER_IND_slt = find_selected_csp_filters(Ns, m, FB_FILTER_IND)\n",
    "\n",
    "                #construct selected csp filters, W_B_slt has shape (2*Ns, num_chls), (8,22) for example\n",
    "                W_B_slt = W_B[FB_FILTER_IND_slt[:,0], :, FB_FILTER_IND_slt[:,1]]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
